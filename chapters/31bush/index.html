<html>	<head>		<meta name="GENERATOR" content="Adobe PageMill 3.0 Mac">		<meta http-equiv="content-type" content="text/html;charset=iso-8859-1">		<title>Temporal Synthesis</title>	</head>	<body bgcolor="#ffffff" link="#0000ff">		<h1><font face="Times New Roman">29. Temporal Synthesis</font></h1>		<h2><font face="Times New Roman">Noel Bush</font></h2>		<p><font face="Times New Roman">It's been two years since this text was written, and I wish I could say that the manner of thinking and set of preoccupations expressed here had been developed further during the intervening time. As it happens, what you see is largely still what you get. However, let this serve as an alert to the interested reader: the C program discussed as part of this piece is being re-realized in Java, not only to overcome some of the troubles of multi-platform use (I was terribly chagrined the first time I tried to compile this thing under Windows) but also to give it a GUI, which it certainly deserves, and hopefully rekindle my (and perhaps others') interest enough to re-awaken the embryonic ideas blubbering forth below.</font></p>		<h3><font face="Times New Roman">Evil Time Machines</font></h3>		</h3>		<p><font face="Times New Roman">As a composer who works in the medium of computer synthesis (among others), I am cognizant -- like many -- of some of the unconsidered habits of mind that can creep into the creative process out of the technological &quot;environment&quot;. One of those habits of mind that concerns me greatly is the -- quite natural -- tendency when using computers to compose to think of &quot;time&quot; in the clock sense, and to allow the tick-marks of minutes and seconds to become the invisible skeleton around which a piece of music is hung. There are inevitable consequences to having to &quot;express&quot; every &quot;event&quot; in a quantificational scheme that is absolute and wholly from-without. One of those consequences -- the primary one, or the one that troubles me most -- is the likelihood that the music produced is highly metricalized, that ideas which do not easily translate to the track/second metaphor are forced to do so, and that overall the composer is left to either struggle or conform. In either case some music is getting lost. At least, I know that some of my music gets lost.</font></p>		<p><font face="Times New Roman">So this study began with a question, posed in hopes of using computers to realize otherwise unrealizable ideas, but in a way that is free from the aesthetic tyranny of the great &quot;time machine&quot;. The question: <i>How might a musical system for computer synthesis organically integrate temporal structure with sonic organization?</i></font></p>		<p><font face="Times New Roman">Obviously there's at least one presupposition here, as well as an implied modus operandi. The presupposition has to do with what &quot;organic&quot; means. Without diverging too much, I'll simply say that it's left somewhat open, only loosely defined from the outset as (approximately) &quot;made of the same stuff as&quot;. So this is a preference for &quot;tightly knit wholes&quot; rather than disparately-origined interlinked modules. The implied modus operandi is expressed in the term &quot;musical system&quot;. Whatever this may or may not &quot;mean&quot; in general, all that it's intended to convey here is that I set out to compose by assembling something I called a &quot;system&quot; -- perhaps, but not necessarily, a set of rules, or a concept, or an algorithm -- simply a collection of storable predispositions that could be used more than once as the primary engine of a compositional endeavor.</font></p>		<p><font face="Times New Roman">The following text describes my attempt to develop a prototype of such a system. The tools I used were the C language, the Cscore function library, and Csound. The tools were simply a choice of technology. However, the strategy I chose for using these tools was much more calculated. I decided that I should <i>draw</i> my music -- without first knowing <i>how</i> the drawing was supposed to mean.</font></p>		<p><font face="Times New Roman">So the <a href="#fig1">drawing</a> I began with was conceived as the raw image of a primary piece of music yet unheard. Rather than create my system and <i>then</i> just let it &quot;output&quot; its music, I decided to regard the drawing as a full-fledged score, <i>for which</i> I had to create the appropriate system in order to hear the music. I wanted to reverse engineer my own intuitive compositional system, so to speak.</font></p>		<p><font face="Times New Roman">Again: I directed my efforts toward producing a musical system in which &quot;time&quot; would not function as an axis against which &quot;sound&quot; &quot;happens&quot;, but instead in which sound and time would manifest (theoretically at least, but hopefully experientially) as inextricably linked properties of the whole music. In the system I would construct, all the &quot;times&quot; of a piece -- all relations and correspondences observed purely <i>within</i> the system, not mere measured quantities -- would be truly organic and manipulable aspects of the music rather than as gridlines laid over static values of &quot;pitch&quot;, &quot;interval&quot;, etc.</font></p>		<h3><font face="Times New Roman">Reverse Engineering an Inner Composer</font></h3>		</h3>		<p><font face="Times New Roman">This approach was, truly, expressed in negative terms -- formulated around all of the things I wished to avoid. But my assumption was that there was something &quot;within me&quot; that I would be very interested in hearing, if only I could get rid of the computer-imposed requirements to &quot;express&quot; everything in pseudo-programming languages.</font></p>		<p><font face="Times New Roman">From my point of view, methods of sound generation should follow from, rather than guide, issues of structure. I focus on the more abstract layers of the compositional process, because I regard these concerns as nearly primary in relation to the nature of the activity of composing, and overridingly compelling as <i>reasons to compose </i>in the first place. I define &quot;progress&quot;, personally, as any development in the lucidity for myself of my creative aspirations. I borrow theory, concepts, and techniques as needed, for raw materials of creative exploration. The ur-text and the methodology may completely dissolve away in the finished &quot;product&quot;, as far as I'm concerned. I could care less about the name of an algorithm or the structure of some &quot;chord&quot;.</font></p>		<p><font face="Times New Roman">That said, I should make it clear that composing specifically with computers is personally of deep interest. For me, the ultimate appeal of the computer as a medium for composition lies not in its putative ability to produce &quot;any sound one can imagine&quot;, nor in its utility for automating and precisely executing process-complexes which would otherwise require a skilled human (or superhuman) contingent to faithfully carry out. The true allure of the computer beckons from the perennially extensible reaches of abstraction into which it can deliver the composer. Music can arise that makes its sense within worlds unimaginable or inaccessible without the participation of the computer. &quot;Getting there&quot; and &quot;being there&quot;, in terms of the making and experiencing of a piece of music, have a vividness that the computer, specifically, enables. The composer's journey from the first compositional urge, through all its ramifications and intermediary states, to the &quot;final piece&quot; (if such ever crystallizes) receives deep exposure, for the perusal of both composer and others, thanks to the hard documentary evidence of the computer code which undergirds the compositional endeavor. The required precision creates an exceptional potential for theoretical refinement and specialization.</font></p>		<p><font face="Times New Roman">We all know that a large gap separates &quot;new sounds&quot; from &quot;new music&quot;. This problem looms particularly large for a computer composer who wishes to discover how to make a leap from clever synthesis algorithms to a <i>sui generic</i> piece without falling short upon a macrostructural arrangement of algorithm-objects that has less compositional intensity than the signal-level synthesis project has precision. While computer composers may create wildly original &quot;sounds&quot; and &quot;textures&quot;, the musical structure which holds these objets d'art together remains at best an imported formality or at worst an ad hoc assemblage. This is regrettable if one seeks not only new content, but also new meaning in &quot;new media&quot;.</font></p>		<p><font face="Times New Roman">The interface a computer composer chooses exerts an indelible influence on the music produced. Awareness of the nature of this influence enables us to emphasize desirable aspects and avoid unwanted effects. Minimally, when composing with computers, I wish to tease out the conceptual framework that infuses the system in use. Better still, I may actively construct the conceptual framework itself. The computer affords a rare opportunity to describe not only what will happen, but exactly how it will happen, and indeed what that &quot;what&quot; &quot;is&quot;.</font></p>		<p><font face="Times New Roman">For the purposes at hand, I view programming as a creative process in which, instead of predefining my goal(s) (e.g., to simulate a natural instrument) and then evaluating my subsequent work based upon how close it comes to the mark, I rather place my compositional aims <i>within </i>the feedback loop that includes my work with the computer and the output it provides me. So the question of how to make the sound of a drawing (or some other input) avoids tautological concerns of <i>could</i> or <i>should</i> -- becoming, in fact, even <i>more</i> than a determination of how I <i>want</i> to interpret it -- and reveals itself instead as a matter (not a question or a determination) of how it <i>happens that it gets interpreted</i>, as an integral fact of the story of the entire compositional endeavor.</font></p>		<h3><font face="Times New Roman">Some Nice Curves<br>		</font></h3>		</h3>		<p><font face="Times New Roman"></font><a name="fig1"></a><img src="figures/tract.gif" alt="tract curve" width="843" height="641" naturalsizeflag="3" align="BOTTOM"><br>		</p>		<p><b><font face="Times New Roman">Figure 1</font></b></p>		<p><font face="Times New Roman">I regarded the curve I drew, pictured above (<a href="#fig1">Figure 1</a>), as the image of the piece I would compose. I set myself the imperative to discover the curve's music through the development of a system characterized as a) &quot;organic&quot; in its relationship to the drawing, b) as &quot;self-contextual&quot; as possible, and c) where not purely self-contextual, at least not arbitrary in its borrowed forms. As an expression of compositional aims, this statement functions as a means of focusing my project metaphorically and conceptually.</font></p>		<p><font face="Times New Roman">Determining how my program might read the image required that I define an attitude about my view of the drawing. I decided (well, I was pretty well prejudiced from the start) that this drawing did not suggest an &quot;<i>x-y</i> graph&quot; which plots the change in one value on one axis against the change in another value, least of all a &quot;something over <i>time</i>&quot; graph. Instead it looked to me like a path: a path for one to follow as though one travels along the line: turning with it, speeding up and slowing down with it, feeling the motion internally as one feels music. One approach to the interpretation of this concept mathematically, working solely from the image, might read the path as a parametric curve, in which a third vector-call it t-moves along the line, itself an ordered list of (<i>x, y</i>) coordinate pairs.</font></p>		<p><font face="Times New Roman">This data table had two properties which seemed useful to the structuring of a &quot;self-contextual&quot; system: the values in each of the coordinate pairs <i>related to each other</i> meaningfully-i.e., &quot;t-meaningfully&quot; -- and the <i>order</i> of the coordinate pairs factored equally critically in the &quot;meaning&quot; of the datafield as a whole.</font></p>		<p><font face="Times New Roman">I interpreted this as a diagram of a time structure, from at out-of-time perspective. I envisioned a particle or a being moving along the curve, as t, at perhaps even a constant rate, in a path described by the (<i>x</i>, <i>y</i>)-pair data table. I imagined that this particle/organism might, for instance, experience inertial forces due to the angle of its motion, thus altering its speed, changing its &quot;muscle tension&quot;, etc. By viewing the changes in (<i>x</i>, <i>y</i>) pairs through t, I saw that I gained a systemic view of the situation in which t functioned as a <i>time shape</i>, rather than as a mere &quot;axis of time&quot;.</font></p>		<p><font face="Times New Roman">The matter of reading the drawing thus became a task of assigning correspondences between the curve and the <i>music</i> in development, rather than between the curve and &quot;the sound&quot;. The drawing would determine all the different aspects of the eventual sound. I might pull some values directly; I might derive others as secondary or tertiary results of more direct measurements. I began simply by deriving pitch values from both the <i>x</i> and <i>y</i> coordinates (the very thought!). By choosing to use pitches rather than frequency values, I strengthened the relational qualities within the curve. Although I introduced a registral dimension later in the construction of the piece, for the initial reading I left the pitch range open (i.e., classless).</font></p>		<p><font face="Times New Roman">I regarded this first reading of the curve as only a start: the reference-background for the music. With the aid of the Cscore functions, my prototype C program generated a score, and a simple Csound orchestra synthesized the crudest sonic sketch. This first result, a pair of plodding parallel pitch-successions, each at least as noncommittal on its own as a walking bass stripped of its context, already suggested intervallic systematization, but still manifested a good bit less than a full harmonic system.</font></p>		<p><font face="Times New Roman">I had already decided that event durations, dynamics and timbre, apparent spatial locations, and all other qualities would derive from the same curve. I sought multiple ways of reading the same data which stayed consistent with the initial &quot;organic&quot; metaphor of a moving body. For example, notes in a tighter part of the curve might happen faster-or have shorter durations-than those in looser segments. Quantizing these durations would add a dimension of relative meaning among the notes. I developed timbre in a similar way, by generating spectral profiles according to, for instance, the comparison between the durational and pitch aspects of a note against its immediate neighbors. I derived all other qualities of the initial notelist in a similar manner. (See <a href="source/instr_1c.html#instr_1">instrument 1</a>.)</font></p>		<p><font face="Times New Roman">I laid the subsequent course of this enterprise as the enfolding of more and more articulations into the whole of the becoming-music by means of secondary process layers that would get generated along with the already severalfold recursively-derived qualities. The process which grew into my C program, <i><a href="source/subsub.html">subsub</a></i>, began as a substitution or &quot;enriching&quot; process, using a method called &quot;reach&quot; which constructed the sound musically: extrapolating enriched versions of the curve-directed reference background by using the curve to guide successive selection and transformation of segments of the originary material.</font></p>		<p><font face="Times New Roman">Although I used conventional terms and synthesis methods, I employed them with different aims. I approached the creation of the total sound as a multi-level, multi-scale, evolutionary whole-piece process. This method differed greatly from ornamentation in that the latter usually makes little intrusion upon the time-structure of the music being &quot;gussied up&quot;, whereas my process treated all temporal qualities of the proto-musical material being enriched as just as malleable as harmonic and other qualities, recognizing &quot;harmonic&quot;, &quot;rhythmic&quot;, and other aspects of music as truly inseparable from &quot;time&quot;. I did not plot events against time; rather, the events themselves &quot;plotted&quot; and created time (not &quot;filled&quot; it).&nbsp;</font><a name="processdescription"></a>A partial description of the process follows:</p>		<p><font face="Times New Roman">Start with a series of elements (with pitch, durational, and other qualities) derived from the curve as described above. Call this originary series <i>R</i> (for &quot;raw&quot;).</font></p>		<p><i><font face="Times New Roman">R</font></i><font face="Times New Roman"> has <i>n</i> elements, each notated as an &quot;<i>r</i>&quot; with a subscript:</font></p>		<p><i><font face="Times New Roman">R </font></i><font face="Times New Roman">=<i> </i>{<i>r<sub>0</sub></i>,<i> r<sub>1</sub></i>,<i> r<sub>2</sub></i>, ... ,<i> r<sub>n</sub></i>}</font></p>		<p><font face="Times New Roman">Generate the enriched series, <i>P</i> (for &quot;processed&quot;), by the following method.</font></p>		<p><font face="Times New Roman">Read through <i>R</i>, one element at a time. Call each step through <i>R</i> (which corresponds to a discrete change in t) a &quot;<i>T</i>-step&quot;, and let it correspond to<i> </i>an associated subseries <i>R'<sub>t </sub></i>(&quot;<i>R</i> prime sub <i>t</i>&quot;). Call the set of all <i>t</i>-values <i>T</i>:</font></p>		<p><i><font face="Times New Roman">T </font></i><font face="Times New Roman">= {0, 1, 2, ..., <i>n</i>}</font></p>		<p><font face="Times New Roman">At each <i>T</i>-step, read from the curve a &quot;reach&quot; value integer <i>a</i> (based on, e.g., tightness, steepness, direction) contstrained such that:</font></p>		<p><font face="Times New Roman">0 <i>&plusmn; t </i>&lt; <i>a </i>&lt; <i>n &plusmn; t</i></font></p>		<p><font face="Times New Roman">Each <i>R'<sub>t</sub> </i>has <i>a</i> + 1 elements. Generate subseries <i>P'<sub>t</sub></i> by processing each element of <i>R'<sub>t</sub></i> (exemplified below).</font></p>		<p><font face="Times New Roman">Notate each corresponding element of <i>R'<sub>t</sub></i> and <i>P'<sub>t</sub></i> as an &quot;<i>r</i>&quot; or a &quot;<i>p</i>&quot;, respectively, with a subscript &quot;<i>u</i>&quot;. Call the set of all <i>u</i>-values <i>U</i>:</font></p>		<p><i><font face="Times New Roman">U </font></i><font face="Times New Roman">= &plusmn;{<i>t</i>, <i>t + 1</i>, <i>t + 2</i>, ..., <i>t + (a &plusmn; 2)</i>, <i>t + (a</i> &plusmn; <i>1)</i>, <i>t + a</i>}</font></p>		<p><font face="Times New Roman">Thus:</font></p>		<p><i><font face="Times New Roman">P'<sub>t</sub></font></i><font face="Times New Roman"> = {<i>p<sub>t</sub> </i>, <i>p<sub>t</sub></i><sub> </sub>+ 1 , <i>p<sub>t</sub></i> + 2 , ..., <i>p<sub>t</sub> </i>+ (<i>a</i> &plusmn; 1) , <i>p<sub>t</sub></i> + (<i>a</i> &plusmn; 2) , <i>p<sub>t</sub></i> + <i>a</i> } &lt;=&gt;</font></p>		<p><i><font face="Times New Roman">R'<sub>t</sub></font></i><font face="Times New Roman"> = {<i>r<sub>t</sub> </i>, <i>r<sub>t</sub> </i>+ 1 , <i>r<sub>t</sub></i> + 2 , ..., <i>r<sub>t</sub></i> + (<i>a</i> &plusmn; 1) , <i>r<sub>t</sub> </i>+ (<i>a</i> &plusmn; 2) , <i>r<sub>t</sub></i> + <i>a</i> }</font></p>		<p><font face="Times New Roman">(or <i>P'</i><sub>t</sub> = {<i>p<sub>t</sub> </i>, <i>p<sub>t</sub></i> &plusmn; 1 , <i>p<sub>t</sub></i> &plusmn; 2 , ..., <i>p<sub>t</sub></i> &plusmn; (<i>a</i> + 1) , <i>p<sub>t</sub></i> &plusmn; (<i>a</i> + 2) , <i>p<sub>t</sub></i> &plusmn; <i>a</i> } &lt;=&gt;</font></p>		<p><font face="Times New Roman">R<i>'</i><sub>t</sub> = {<i>r<sub>t</sub> </i>, <i>r<sub>t</sub></i> &plusmn; 1 , <i>r<sub>t</sub></i> &plusmn; 2 , ..., <i>r<sub>t</sub></i> + (<i>a</i> &plusmn; 1) , <i>r<sub>t</sub></i> + (<i>a</i> &plusmn; 2) , <i>r<sub>t</sub> </i>&plusmn; <i>a</i> } )</font></p>		<p><font face="Times New Roman">One element-process: where &quot;D(<i>e</i>)&quot; signifies the durational quality of any element <i>e</i>,</font></p>		<p><font face="Times New Roman">D(<i>p<sub>u</sub></i>) = [D(<i>r<sub>u</sub></i>) &divide; D(<i>r<sub>t</sub></i> --&gt; <i>r<sub>u</sub></i>)] &middot; D(<i>r<sub>u</sub></i>).</font></p>		<p><font face="Times New Roman">Thus the durational quality of the processed subseries <i>P'<sub>t</sub></i>,<i> </i>having the same number of elements as the raw subseries <i>R'<sub>t</sub></i>, has a durational quality equivalent to that of the corresponding element <i>r<sub>t</sub>.</i></font></p>		<p><font face="Times New Roman">Another element-process: where &quot;P(<i>e</i>)&quot; signifies the pitch quality of any element <i>e</i>, and PI(<i>e</i> --&gt; <i>f</i>) signifies the interval from P(<i>e</i>) to P(<i>f</i>):</font></p>		<p><font face="Times New Roman">P(<i>p<sub>u</sub></i>) = P(<i>r<sub>u</sub></i>) + PI(<i>r<sub>t</sub></i> --&gt; <i>p<sub>t</sub></i>)</font></p>		<p><a href="#fig2"><font face="Times New Roman">Figure 2</font></a><font face="Times New Roman">, in conventional musical notation (admittedly unwieldy for these purposes), shows several sequential <i>P'<sub>t</sub></i> derivations, using just these two element-processes, given an arbitrary series of <i>a</i>-values {7, 3, -2, -5, -3, 2, 8}. In the example, each <i>P'<sub>t</sub> </i>subseries begins beneath its corresponding <i>r<sub>t</sub></i>.<br>		</font></p>		<p><font face="Times New Roman"></font><a name="fig2"></a><img src="figures/musex.gif" height="280" width="572" naturalsizeflag="0" align="BOTTOM"><br>		<br>		</p>		<p><b><font face="Times New Roman">Figure 2<br>		</font></b></p>		<h3><font face="Times New Roman">SubSub (tract)</font></h3>		<p><font face="Times New Roman">The method described above comprises the heart of the C program <i><a href="source/subsub.html">subsub</a></i>. I did not conceive <i><a href="source/subsub.html">subsub</a></i> as a general-purpose algorithmic music program; its specialization to the concerns at hand makes it unsuited for multiple uses. I desgined the program <i>solely</i> for the rendering in sound of a single piece. I regard all versions of the program and its <a href="source/intractorc.html">companion Csound orchestra</a>, and all sound results produced thereby, as more or less accurate realizations of the musical piece that satisfies me as a sounding of the originary drawing.</font></p>		<p><font face="Times New Roman">I have divided this enterpise into two distinct phases, signified by two different piece names generally used together with a slash: <i>tract,</i> which sounded the curve pictured in <a href="#fig1">Figure 1</a>, and <i>intract,</i> which continued the development of <i>subsub </i>and the <a href="source/intractorc.html">companion orchestra</a>, but took as its source a new curve, shown in <a href="#fig3">Figure 3</a>.</font></p>		<p><font face="Times New Roman">I drew this curve in an imaginative extrapolation upon the concepts under development. Listening to the sound output that <i>subsub</i> and the <i>tract</i> orchestra at a particular stage in the compositional process produced, I created this image acting as a human version of the <i>subsub</i> engine in reverse. Literal accuracy aside, I intended to further interpenetrate the metaphorical compositional precepts with the synthetic-algorithmic program structure. I plotted the new curve as a new datafield (&quot;minspec&quot; in <i>subsub</i> terms), this time using much smaller <i>T</i>-steps to attain a finer degree of curve-matching (i.e., accuracy of t), and then the programming-compositional exercise continued its evolution.</font></p>		<p><a href="source/subsub.html"><i><font face="Times New Roman">Subsub</font></i></a><i><font face="Times New Roman"> </font></i><font face="Times New Roman">derives timbre, spatial location, and other parameters using similar processes. In pursuit of &quot;self-contextuality&quot; for the piece, I introduced a second-order process, &quot;tally&quot;, which derives some qualities including dynamics. <i><a href="source/subsub.html">Subsub</a></i>'s <a href="source/instr_1c.html#instr_1">instr_1()</a>, <a href="source/instr_2c.html#instr_2">instr_2()</a> and <a href="source/instr_4c.html#instr_4">instr_4()</a> modules have one-dimensional arrays called <i>tally</i> with size <i>number-of-pitch-classes. </i>As the program derives both the <i>R </i>series and the <i>P </i>series, the <i>tally</i> array keeps a running count of the number of occurences of each pitch-class as of any moment in the piece, and uses these values as a weighting mechanism to influence or determine local sound-qualities of an event.<br>		</font></p>		<p><font face="Times New Roman"></font><a name="fig3"></a><img src="figures/intract.gif" height="380" width="481" naturalsizeflag="0" align="BOTTOM"><br>		</p>		<p><b><font face="Times New Roman">Figure 3<br>		</font></b></p>		<p><font face="Times New Roman">I preserved the pairing aspect of the <i>subsub</i> process throughout the entire organization of the program-orchestra suite: each &quot;event&quot; consists of a pair of notes, both of whose parameter sets get included in the same i-line in the Csound scorefile generated. This makes for almost double the number of p-fields that the scorefile would have included if it instead listed <i>x</i>- and <i>y</i>-derived events as individual i-lines, but I found the pairing essential to the realization of the piece, because the pairs share parameter values even in the orchestra. I didn't care that the program could have easily duplicated any shared values between two events, because I wanted to maximize the extent to which the structure of the piece pointed toward interrelatedness of all events. In truth, I regard the Csound <a href="source/intractsco.html">scorefile</a> as the <i>worst </i>place to look for the musical structure of the piece, short of the <a href="source/intractorc.html">orchestra</a> itself which reveals almost nothing; the piece's intended character and specificity reside in the pairing of <i><a href="source/subsub.html">subsub</a> </i>with the originary curve (either the <i><a href="#fig1">tract</a></i> or the <i><a href="#fig3">intract</a></i> image).</font></p>		<p><font face="Times New Roman">Cscore simplifies some of the aspects of relative element references by using pointers. I used Cscore, along with some simple array structures, and coupled with a C macro set of <i>#define</i>s that developed along with the program (see <i><a href="source/defgh.html">defg.h</a></i>, <i><a href="source/defdh.html">defd.h</a></i>, and <i><a href="source/defsh.html">defs.h</a></i>), to create the language with which <i><a href="source/subsub.html">subsub</a> </i>talks about and builds the scorefile for Csound. (The macros mostly made it easier to keep track of p-field numbers; no doubt a skilled programmer could substitute a system more flexible than the one in use here.) I could thus create variants on the enriching process described above with ease, as <i>for</i>-loops involving arrays and pointers. An excerpt from <i><a href="source/instr_4c.html">instr_4.c</a> </i>follows that demonstrates the use of Cscore with the p-field macros, and the tally function.</font></p>		<p><b><tt><font face="Courier New">1</font></tt></b><tt><font face="Courier New">?int instr_4(int bat)<br>		?{<br>		?...<br>		<b>2</b>?for(evnum=beg, q=0; q&lt;numnotes; q++, i1ev++) {<br>		?...<br>		<b>3</b>?reach=(*i1ev)-&gt;p[I1_RCH];<br>		<b>4</b>?pchdiff1=<br>		?((*i1ev)-&gt;p[I1_PCH1])-((*(i1ev+reach))-&gt;p[I1_PCH1]);<br>		<b>5</b>?pchdiff2=<br>		?((*i1ev)-&gt;p[I1_PCH2])-((*(i1ev+reach))-&gt;p[I1_PCH2]);<br>		<b>6</b>?for(r=0; abs(r)&lt;abs(reach); r+=dir, evnum++, i4ev++) {<br>		?...</font></tt><font face="Courier New"><br>		</font><a name="excerptline7"></a><b><tt>7</tt></b><tt>?(*i4ev)-&gt;p[I4_PCH1]=quant(fbetw(<br>		??((*(i1ev+r))-&gt;p[I1_PCH1])+pchdiff2,<br>		??absminpch,absmaxpch),pcsize);<br>		<b>8</b>?(*i4ev)-&gt;p[I4_PCH2]=quant(fbetw(<br>		??((*(i1ev+r))-&gt;p[I1_PCH2])+pchdiff1,<br>		??absminpch,absmaxpch),pcsize);<br>		<b>9</b>?(*i4ev)-&gt;p[I4_PC1]=pc1=pc((*i4ev)-&gt;p[I4_PCH2]);<br>		<b>10</b>?(*i4ev)-&gt;p[I4_PC2]=pc2=pc((*i4ev)-&gt;p[I4_PCH1]);<br>		<b>11</b>?notetime+=(20/(pc1+pc2+2))*((*i4ev)-&gt;p[II_DUR]);<br>		<b>12</b>?tally1[pc1]++;<br>		<b>13</b>?tally2[pc2]++;<br>		?...</tt><br>		<a name="excerptline14"></a><b><tt>14</tt></b><tt>?minatk=gof(absminatk, 0.1*((*i4ev)-&gt;p[II_DUR]));<br>		<b>15</b>?maxatk=5*minatk;<br>		<b>16</b>?(*i4ev)-&gt;p[I4_ATK1]=linscale(tally1[pc1],<br>		??tally1[talmax(tally1)],tally1[talmin(tally1)],<br>		??absminatk,maxatk);</tt><br>		<a name="excerptline17"></a><b><tt>17</tt></b><tt>?(*i4ev)-&gt;p[I4_ATK2]=linscale(tally2[pc2],<br>		??tally2[talmax(tally2)],tally2[talmin(tally2)],<br>		??absminatk,maxatk);<br>		</tt></p>		<p><font face="Times New Roman">(The line numbers serve only as arbitrary reference marks.) The macros I used here necessitate <i>more</i> typing (e.g., &quot;<tt>(*i4ev)-&gt;p[I4_ATK1]</tt>&quot; instead of &quot;<tt>(*i4ev)-&gt;p[9]</tt>&quot;), but allow easier updates to the code if I change the number of p-fields.</font></p>		<p><font face="Times New Roman">In the terms used <a href="#processdescription">introduced earlier</a>, with the addition of an <i>x- </i>or <i>y-</i> prefix to the element term, <a href="#excerptline7">line 7</a> amounts to:</font></p>		<p><font face="Times New Roman">P(<i>x-p<sub>u</sub></i>) = P(<i>x-r<sub>u</sub></i>) + PI(<i>x-r<sub>t</sub></i> --&gt; <i>x-p<sub>t</sub></i>),</font></p>		<p><font face="Times New Roman">with the additional stipulation that P(<i>x-p<sub>u</sub></i>) must not fall outside of a pre-specified pitch-range-the <i>fbetw() </i>function preserves pitch-class while bringing the value within the range-and that P(<i>x-p<sub>u</sub></i>) gets quantized to a pitch-class value. In this case I used <i><a href="source/calc.html#quant">quant()</a></i> (defined in <i><a href="source/calc.html">cal.c</a></i>) as a lazy safeguard against the possibility that I had lost alignment to the pitch-class somewhere in the &quot;curve --&gt; <i>fullplex--&gt; instr_1()</i>&quot; process, but elsewhere in <i>subsub </i>I used <i><a href="source/calc.html#quant">quant()</a></i> to allow conversant use of non-quantized pseudo-pitches or frequency values and regular pitch-class values.</font></p>		<p><font face="Times New Roman">The above code fragment also demonstrates the use of <i>tally </i>and its companion functions <i><a href="source/scoc.html#talmax">talmax()</a> </i>and <i><a href="source/scoc.html#talmin">talmin()</a> </i>(see <i><a href="source/scoc.html">sco.c</a></i>), which provide the most- and least-occuring pitch-class value, respectively, as of the present point, and also the essential function <i><a href="source/calc.html#linscale">linscale()</a> </i>(defined in <i><a href="source/calc.html">cal.c</a></i>), which refits any value into a new range based on where it falls within an originary range.<a href="#excerptline17"> Line 17</a> thus says, &quot;The attack value for (<i>x-p<sub>u</sub></i>) falls within the range of minimum and maximum allowable attacks (derived in <a href="#excerptline14">lines 14 and 15</a> from the duration of (<i>x-p<sub>u</sub></i>) and limited by an absolute minimum) in direct proportion to where the number of occurences, as of this moment, of pitch-class of (<i>x-p<sub>u</sub></i>) falls within the current picture of the number of occurences, as of this moment, of all pitch-classes.&quot;</font></p>		<p><font face="Times New Roman">The </font><a href="source/intractorc.html"><i><font face="Times New Roman">tract/intract</font></i><font face="Times New Roman"> orchestra</font></a><font face="Times New Roman"> does not employ any particularly unusual synthesis algorithms. <i><a href="source/intractorc.html#instr1">Instr 1</a></i>, which plays the &quot;reference background&quot; (<i>R</i>), consists of a simple bandpass filtered white noise instrument. <i><a href="source/intractorc.html#instr2">Instr 2</a></i> and <i><a href="source/intractorc.html#instr4">instr 4</a></i>, which each play a variant <i>P </i>series, use similar subtractive synthesis methods, with quite a bit of duplicated code. <i>Instr</i>s <a href="source/intractorc.html#instr91">91</a>, <a href="source/intractorc.html#instr92">92</a> and <a href="source/intractorc.html#instr94">94</a> provide global reverb for the three main instruments. (The spatialization algorithms, my own primitive attempts to realize a spatial reverb model, owe most of their inspiration to the Winter 1995 issue of <i>Computer Music Journal. </i>My model lacks sophistication, falls short of physical accuracy, and adds tremendous bulk to the code: its introduction ballooned the processing time of the <i>intract </i>piece on my crusty old NeXTstation from approximately 24 hours to ten days! At the very least, one might better achieve the desired results with a well-coded ugen.)</font></p>		<h3><font face="Times New Roman">Inconclusion</font></h3>		</h3>		<p><i><font face="Times New Roman">Tract/intract</font></i><font face="Times New Roman"> has gone through a long and torturous evolution, landing here on your doorstep a some kind of protoplasm -- certainly on the way to becoming. I have noted with great interest that while successive generations of the piece have differed from one another both in event-to-event character and &quot;overall sound&quot;, a particular continuity of sensibility has linked them all. A strong sense of &quot;a way of happening&quot; pervades all of the versions of this piece. I attribute this to the structural-metaphorical focus of my compositional attention to the project. The music of <i>tract/intract </i>seems a very &quot;inner&quot; sort. Its reference-structures so tightly interweave with one another to form the fabric of the music, with no associative acknowledgements to an other world either in outer signs or inner pulses, that its nature seems inexplicable, its motives dubitable.</font></p>		<p><font face="Times New Roman">&quot;Temporal Synthesis&quot; does not euphemistically indicate automatic music, and does not involve any form of artificial intelligence. Like methods of sound synthesis, methods of temporal synthesis comprise a varied and expandable set of tools, some of which may have application only in a single creative work. Unlike methods of sound synthesis, methods of temporal synthesis cannot easily quantify their &quot;effects&quot; or proper use. Composing with methods of temporal synthesis necessitates an all-or-nothing approach in that rather than employing techniques priorly made available for application, the composer must develop a temporal meta-construct that pervades the entire work. Specific processes manifest as coded incarnations of the originary form.</font></p>		<p><font face="Times New Roman">Temporal synthesis rejects the notion of time as a medium in which static objects flow or get arranged. If the media in use do not possess enough permeability to fuse with the temporal meta-construct, then they cannot serve as appropriate media for temporal synthesis. This makes music in sound the ideal medium for temporal synthesis. The methods of temporal synthesis used in a musical work must lie on a continuum with the sound synthesis methods, so that the composition of the time truly begins at zero. Works of temporal synthesis demand for their full realization an open-ended composing schedule, and require that the composer attentively follow through all of the implications of the overall concept.</font></p>		<p><font face="Times New Roman">The promise of faster and more efficient computer processors holds one part of the key to the proliferation of works of temporal synthesis. But far greater importance lies with the interface used by the computer composer. An environment like Csound, supplemented by custom C language modules, provides a theoretical &quot;clean room&quot; in which to construct systems which aim for the organic self-contextuality of temporal synthesis. Maintaining low-level access to the parameters of sound generation, and providing a wide variety of algorithms with the ability to expand at any time, permits the composer to build temporal structure into a musical work at the lowest level of relevance. Here stands the open door to future works of undreamt experiential substance and quality.</font>	</body></html>