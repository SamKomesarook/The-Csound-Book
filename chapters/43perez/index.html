<HTML>  
<HEAD>
  <META NAME="GENERATOR" CONTENT="Adobe PageMill 3.0 Mac">
  <META HTTP-EQUIV="content-type" CONTENT="text/html;charset=iso-8859-1">
  <TITLE>Extending Timbral Possibilities for Mixed Ensembles</TITLE>
  <!-- This HTML document was generated by PageMaker -->
  <!-- On Wed Jul 23 12:45:02 1997 from "Untitled-2" -->
</HEAD>
<BODY BGCOLOR="#eeeeee">

<H1><FONT FACE="Times New Roman">41. Extending Timbral Possibilities
for Mixed Ensembles</FONT></H1>

<H2><FONT FACE="Times New Roman">Ileana Perez Velazquez</FONT></H2>

<P><FONT FACE="Times New Roman">Since the 60's, computer programs
such as Music V and Csound have been used to implement algorithms
that simulate acoustic instruments. The resultant spectral content
produced by the Csound instrument can be close to that produced
by acoustic instruments. The Csound instrument can be designed
so that the spectral content of a sound source varies through
time. The spectral content can also change in relationship with
the fundamental pitch. These reasons have inspired some composers
that have used Csound orchestras as extensions of acoustic instruments
in compositions for instruments and tape.</FONT></P>

<P><FONT FACE="Times New Roman">The flexibility of the structure
of Csound allows the creation of imaginary instruments that could
contain features of two or more instruments. We can also design
instruments with characteristics of both instrumental and vocal
sounds. These possibilities provide a vast range for imagination
and creativity.</FONT></P>

<P><FONT FACE="Times New Roman">As composers and performers have
pushed acoustic instruments beyond traditional boundaries using
extended techniques, Csound can open frontiers in extending these
new sound sources. The resultant sounds can be used in combination
with acoustic instruments. Instruments that contain some characteristics
of the spectra of sounds produced by extended techniques were
designed in Csound and used as sound files for the tape of <I>Conversations</I>,
a piece for saxophones, bassoon, bass clarinet, and tape I composed
in 1995. The analysis of the spectra of sounds produced by extended
techniques also inspired the general structure of <I>Conversations</I>.
The present chapter will discuss the timbral design, organization,
and structure of <I>Conversations</I>.</FONT></P>

<H3><FONT FACE="Times New Roman">Motivations and Aesthetic</FONT></H3>

<P><FONT FACE="Times New Roman">The composition of <I>Conversations</I>
was begun in response to the question &quot;what if instruments
were able to communicate as directly as speech?&quot; Much of
the composition process of the piece was the working out of this
metaphor between the sound of the live instruments and the sound
of speech. The need for air by both voice and wind instrumental
sounds suggested the idea of mixing resynthesized voice sounds
with live and recorded instrumental sounds.</FONT></P>

<P><FONT FACE="Times New Roman">In this piece both instruments
and tape communicate in an imaginary language. The tape contains
numerous passages where woodwind sounds are applied to the frequency
contour of speech. Often, while playing multiphonics, the instrumentalists
are asked to sing, speak, and at some climatic points, even scream.
This helps give the piece an overall quality of &quot;voiceness.&quot;</FONT></P>

<H3><FONT FACE="Times New Roman">Multiphonic Spectra of Sound
Sources</FONT></H3>

<P><FONT FACE="Times New Roman">Samples of bass clarinet and saxophone
multiphonic sounds were analyzed using software called Lemur by
Bill Walker and Kelly Fitz. The graphs obtained from the analysis
of bass clarinet multiphonics showed formant regions where the
energy was concentrated. Figure 1 is one example of the spectrum
of bass clarinet multiphonic produced by simultaneously vocalizing
into the instrument while playing it.<BR>
</FONT></P>

<P><FONT FACE="Times New Roman"><IMG SRC="figures/01.gif" WIDTH="724"
HEIGHT="536" NATURALSIZEFLAG="3" ALIGN="BOTTOM"></FONT></P>

<P><B><FONT SIZE="-1" FACE="Times New Roman,Georgia,Times">Figure
1</FONT></B><FONT SIZE="-1" FACE="Times New Roman,Georgia,Times">
One example of the spectrum of bass clarinet multiphonic produced
by simultaneously vocalizing into the instrument while playing
it.</FONT></P>

<P><FONT FACE="Times New Roman"><IMG SRC="figures/2.gif" WIDTH="860"
HEIGHT="638" NATURALSIZEFLAG="3" ALIGN="BOTTOM"></FONT></P>

<P><B><FONT FACE="Times New Roman">Figure 2</FONT></B><FONT FACE="Courier New">
</FONT><FONT FACE="Times New Roman">An example of the spectrum
of an overblown multiphonic which shows formants that make a glissando
shape through time.<BR>
</FONT></P>

<H2><FONT FACE="Times New Roman">Processes: FOF and LPC</FONT></H2>

<P><B><FONT FACE="Times New Roman">Synthese par fonctions d'onde
formantiques ( FOF )</FONT></B></P>

<P><FONT FACE="Times New Roman">FOF is a well known technique
for synthesizing the timbre of sung vowels (Xavier Rodet). The
lowest five formants are individually controlled to simulate the
resonances of the singing voice. Using the FOF opcode of Csound,the
fundamental frequency of each vowel sound, the vibrato characteristics,
the amplitude, and the frequency of each formant were specified
using the values given by Rodet (Dodge and Jerse, 1985). In some
cases, the value given to the fundamental frequency of the formants
were those frequencies from the formants found in the analysis
of multiphonics. In other cases the mixture of the sounds obtained
by this process with sound files of recorded multiphonics eliminate
some of the characteristic of roughness of certain multiphonics.</FONT></P>

<P><FONT FACE="Times New Roman">FOF technique produced sound files
of vowel timbre that created glissandi similar to those found
in the analysis of overblown multiphonics. The starting points
of the glissandi of the formants come from the frequency of the
upper and lower borders of the formants of the analyzed multiphonics.
Example 1 shows the implementation of this idea in a csound instrument.</FONT></P>

<P><FONT FACE="Courier New">Example 1.1: Implementation in a Csound
instrumentinstr 1</FONT></P>

<P><FONT FACE="Courier New">;p4 Fund freq to which formants of
both voices go when descend by glissandi<BR>
;-<BR>
;p15 Fundfreq form1 (FIRST VOICE, FUND FREQUENCIES FROM MULTIPHONIC
SPECTRA)<BR>
;p16 Fundfreq form2<BR>
;p17 Fundfreq form3<BR>
;p18 fundfreq form4<BR>
;p19 fundfreq form5<BR>
;<BR>
;p20 Fundfreq form1 (SECOND VOICE, FUND FREQUENCIES FROM MULTIPHONIC
SPECTRA)<BR>
;p21 Fundfreq form2<BR>
;p22 Fundfreq form3<BR>
;p23 Fundfreq form4<BR>
;p24 Fundfreq form5<BR>
;<BR>
ifreqfrm1=p5 ;formants freq)<BR>
ifreqfrm2=p6 ;(for first and second voice)<BR>
ifreqfrm3=p7<BR>
ifreqfrm4=p8<BR>
ifreqfrm5=p9<BR>
;<BR>
iamplfrm1=p10 ;(amplitude of formants)<BR>
iamplfrm2=p11 ;(applied to both voices)<BR>
iamplfrm3=p12<BR>
iamplfrm4=p13<BR>
iamplfrm5=p14<BR>
;<BR>
kgliss1 linseg p15, p3/2, p4, p3/3, p15, p3/3, p15 ;(kgliss for
fund freq of first ;voice)<BR>
kgliss2 linseg p16, p3/3, p4, p3/3, p16, p3/3, p16<BR>
kgliss3 linseg p17, p3/3, p4, p3/3, p17, p3/3, p17<BR>
kgliss4 linseg p18, p3/3, p4, p3/4, p18, p3/3, p18<BR>
kgliss5 linseg p19, p3/3, p4, p3/4, p19, p3/3, p19<BR>
kgliss1 linseg p15, p3/2, p4, p3/3, p15, p3/3, p15 ;(kgliss for
fund freq of first ;voice)<BR>
kgliss2 linseg p16, p3/3, p4, p3/3, p16, p3/3, p16<BR>
kgliss3 linseg p17, p3/3, p4, p3/3, p17, p3/3, p17<BR>
kgliss4 linseg p18, p3/3, p4, p3/4, p18, p3/3, p18<BR>
kgliss5 linseg p19, p3/3, p4, p3/4, p19, p3/3, p19<BR>
;-<BR>
kgliss6 linseg p20, p3, p4 ;(kgliss of fund freq of second voice)<BR>
kgliss7 linseg p21, p3, p4<BR>
kgliss8 linseg p22, p3, p4<BR>
kgliss9 linseg p23, p3, p4<BR>
kgliss10 linseg p24, p3, p4<BR>
;<BR>
kamp linseg 0, .15*p3, .05, .58*p3, .1, .27*p3, 0<BR>
kamp2 linseg 0, .15*p3, .05, .58*p3, .1, .27*p3, 0<BR>
;<BR>
krand randh (p4*.1), .5<BR>
kvrate1 linseg .1, p3*.001, (p10*.3), p3*.06, (p10*.01), p3*.3,
0;vibrato rate for both ;voices<BR>
kvrate2 linseg .1, p3*.001, (p11*.3), p3*.06, (p11*.01), p3*.3,
0<BR>
kvrate3 linseg .1, p3*.001, (p12*.3), p3*.06, (p12*.01), p3*.3,
0<BR>
kvrate4 linseg .1, p3*.001, (p13*.3), p3*.06, (p13*.01), p3*.3,
0<BR>
kvrate5 linseg .1, p3*.001, (p14*.3), p3*.06, (p14*.01), p3*.3,
0<BR>
;-<BR>
avibdep1 oscil kvrate1, (p4/50)+krand, 1 ;vibrato depth for both
voices<BR>
avibdep2 oscil kvrate2, (p4/50)+krand, 1<BR>
avibdep3 oscil kvrate3, (p4/50)+krand, 1<BR>
avibdep4 oscil kvrate4, (p4/50)+krand, 1<BR>
avibdep5 oscil kvrate5, (p4/50)+krand, 1<BR>
;-<BR>
igranulrise=.003 ;rise time excitation envelope<BR>
idur=.02 ;duration of grain<BR>
igranuldec=.007 ;decay time excitation envelope<BR>
iolaps=500;grain overlaps<BR>
;<BR>
kband linseg 0, p3/2, 6, p3/2, 0 ;formant bandwith<BR>
;-<BR>
;FIRST VOICE<BR>
asig1 fof kamp*ampdb(iamplfrm1), kgliss1+avibdep1, ifreqfrm1,
0, kband, igranulrise, idur, igranuldec, iolaps, 1, 1, p3<BR>
asig2 fof kamp*ampdb(iamplfrm2), kgliss2+avibdep2, ifreqfrm2,
0, kband, igranulrise, idur, igranuldec, iolaps, 1, 1, p3<BR>
asig3 fof kamp*ampdb(iamplfrm3), kgliss3+avibdep3, ifreqfrm3,
0, kband, igranulrise, idur, igranuldec, iolaps, 1, 1, p3<BR>
asig4 fof kamp2*ampdb(iamplfrm4), kgliss4+avibdep4, ifreqfrm4,
0, kband, igranulrise, idur, igranuldec, iolaps, 1, 1, p3<BR>
asig5 fof kamp2*ampdb(iamplfrm5), kgliss5+avibdep5, ifreqfrm5,
0, kband, igranulrise, idur, igranuldec, iolaps, 1, 1, p3<BR>
;-<BR>
;SECOND VOICE<BR>
asig6 fof kamp*ampdb(iamplfrm1), kgliss6+avibdep1, ifreqfrm1,
0, kband, igranulrise, idur, igranuldec, iolaps, 1, 1, p3<BR>
asig7 fof kamp*ampdb(iamplfrm2), kgliss7+avibdep2, ifreqfrm2,
0, kband, igranulrise, idur, igranuldec, iolaps, 1, 1, p3<BR>
asig8 fof kamp*ampdb(iamplfrm3), kgliss8+avibdep3, ifreqfrm3,
0, kband, igranulrise, idur, igranuldec, iolaps, 1, 1, p3<BR>
asig9 fof kamp2*ampdb(iamplfrm4), kgliss9+avibdep4, ifreqfrm4,
0, kband, igranulrise, idur, igranuldec, iolaps, 1, 1, p3<BR>
asig10 fof kamp2*ampdb(iamplfrm5), kgliss10+avibdep5, ifreqfrm5,
0, kband, igranulrise, idur, igranuldec, iolaps, 1, 1, p3<BR>
;-<BR>
asig11=(asig1+asig2+asig3+asig4+asig5+asig6+asig7+asig8+asig9+asig10)*2300<BR>
outs asig11, asig11<BR>
endin</FONT></P>

<P><B><FONT FACE="Courier New">Example 1.2: Score file for Example
1.1</FONT></B><FONT FACE="Courier New"><BR>
f1 0 1024 9 1 1 0<BR>
f2 0 256 7 0 128 1 0 -1 128 0<BR>
;<BR>
;formant freq and amp for a male vowel. The high point of the
glissandi are freq. from ;a multiphonic spectra<BR>
i1 0 14 440 650 1100 2860 3300 4500 0 -8 -13 -12 -19 426 1305
1380 1583 1653 1870 1904 2093 2184 2372 2435<BR>
;-<BR>
;p4=fund freq of lower formant<BR>
i1 7 7 789 609 1000 2450 2700 3240 0 -6 -12 -25 -34 789 1305 1380
1583 1653 1870 1904 2093 2184 2372 2435<BR>
;-<BR>
;formant freq and amp for a male vowel. The high point of the
glissandi are the freq. ;from multiphonic spectra<BR>
i1 14 7 110 609 1000 2450 2700 3240 0 -6 -12 -25 -34 426 1305
1380 1583 1653 1870 1904 2093 2184 2372 2435<BR>
;p4=the fund freq of the higuer formant<BR>
i1 16 7 2524 609 1000 2450 2700 3240 0 -6 -12 -25 -34 426 1305
1380 1583 1653 1870 1904 2093 2184 2372 2435</FONT></P>

<H2><FONT FACE="Times New Roman">Linear Predictive Coding (LPC)</FONT></H2>

<P><FONT FACE="Times New Roman">LPC is a technique for the analysis
and resynthesis of the speech waveform. It is &quot;a procedure
for efficient encoding of the speech wave by representing it in
terms of time-varying parameters related to the transfer function
of the vocal tract and the characteristics of the excitation.&quot;
(Atal and Hanauer, 19..) The analysis used the Winham and Steilitz
algorithms programmed for the Unix environment by Lansky whereas
the resynthesis was implemented using Csound language. &quot;In
the resynthesis of the voice, the excitation source (periodic
pulse for vowels or noise for consonants) is fed through the all-pole
filter to reconstitute the waveform of the speech.&quot; (Dodge,
Jerse, 1985) The coefficients of the all-pole filter for the resynthesis
were determined by the analysis program.</FONT></P>

<P><FONT FACE="Times New Roman">Since LPC separates resonance
(filter coefficients) from excitation source, it is common on
resynthesis to change the speed of the speech without altering
its timbre or fundamental frequency.</FONT></P>

<P><FONT FACE="Times New Roman">Csound provides two types of unit
generators to manipulate LPC analysis files: lpread, which reads
in an analysis file at the k-rate and lpreson and lpfreson, which
implement the recursive filter specified by the analysis file.</FONT></P>

<P><FONT FACE="Times New Roman">In <I>Conversations</I>, the Csound
LPC instrument was utilized to slow down the speed of speech.
A whisper-like sound was produced via a random generator instead
of a pulse generator. The random generator was applied to the
vowel part of the algorhythm in order to change the timbre of
the speech. This was accomplished by simply changing the value
that controls the threshold between voiced and unvoiced segments
of the resynthesized speech. In Csound the threshold is controlled
by kerr, which is used to determine the voice/unvoiced nature
of the excitation..</FONT></P>

<P><FONT FACE="Courier New">Example 3: Csound instrument used
to produce LPC sounds in <I>Conversations</I></FONT></P>

<P><FONT FACE="Courier New">sr = 44100<BR>
kr = 441<BR>
ksmps = 100<BR>
nchnls = 2<BR>
;<BR>
instr 1<BR>
;p3 duration over which resynthesis will occur<BR>
;p4 lpc analysis time where resynthesis should begin<BR>
;p5 lpc analysis time where resynthesis should end<BR>
;p6 transpose<BR>
;p7 function table of GBUZZ<BR>
;p8 control the output<BR>
;p9 file lpc input<BR>
;p10 kerr value get from the lpc analysis file. Controls ;the
threshold between voiced (vowels) and unvoiced ;(consonants) segments<BR>
;p11 control of gbuzz kr (specifies multiplier in the series ;of
amp coefficients, 1 ;is its standard value)<BR>
;<BR>
ktime line p4, p3, p5<BR>
krmsr,krmso,kerr,kcps lpread ktime, p9, 32, 176.4<BR>
;lpread read the analysis file<BR>
;at ktime rate<BR>
;krmsr: root mean square value of the ;residual of analysis. (Can
be used as ;an amplitude parameter)<BR>
;krmso: rms of the original. Could also be ;used as an amplitude
parameter<BR>
;kerr: the normalized error. Determine ;voice/unvoiced nature
of excitation<BR>
;kcps: pitch in cps<BR>
;32 (numbers of poles)<BR>
;176.4 (framerate/sec)<BR>
;-<BR>
if kerr &gt; p10 kgoto voic ;kerr value- threshold voice/unvoiced<BR>
;-<BR>
Example 4. Implementation of crossynthesis using the LPC instrument
of example 3.<BR>
instr 1<BR>
ktime line p4, p3, p5<BR>
krmsr,krmso,kerr,kcps lpread ktime, p9 , 32, 176.4<BR>
;-<BR>
if kerr &gt; p10 kgoto voic;kerr value<BR>
;-<BR>
asig soundin 1 ;soundin for saxophone sound ;replacing the generator
of vowels<BR>
;-<BR>
kgoto filt<BR>
;-<BR>
voic: asig rand krmsr ;random generator of noise for ;consonants<BR>
;-<BR>
filt: aout lpreson asig ;voiced and unvoiced signals ;go through
this filter<BR>
;<BR>
aout gain aout, krmso<BR>
aenv linseg 0,.01,1,p3-.02,1,.01,0,1,0<BR>
;<BR>
out (aout*aenv)*p8<BR>
endin</FONT></P>

<P><FONT FACE="Times New Roman">Multiphonic sounds were analyzed
and resynthesized using LPC techniques. As the system was not
designed to work with multiphonics, the result of the resynthesis
was a high pitched sound with a &quot;raspiness&quot; similar
to the timbre of the glottis. This timbre is heard at the end
of the second and third sections of the tape.</FONT></P>

<H3><FONT FACE="Times New Roman">Structure</FONT></H3>

<P><I><FONT FACE="Times New Roman">Conversations</FONT></I><FONT
 FACE="Times New Roman"> is divided into three sections with a
coda. The first section starts with instruments playing, the second
section starts with the tape while both instruments and tape start
together in the third section. The graph in figure 3 shows the
overall structure of <I>Conversations</I>, illustrating the relationship
between the live instruments and the tape.<BR>
</FONT></P>

<P><FONT FACE="Times New Roman"><IMG SRC="figures/3.gif" WIDTH="467"
HEIGHT="457" NATURALSIZEFLAG="3" ALIGN="BOTTOM"></FONT></P>

<P><B><FONT FACE="Times New Roman">Figure 3<BR>
</FONT></B></P>

<P><FONT FACE="Times New Roman">The structure of the piece was
partially inspired by the spectrum of analyzed multiphonics. The
analysis of some multiphonics show formants widely distributed
during the attack portion of the sound. Later, the formants become
more clearly defined until an identifiable pitch is reached. Afterwhich
the frequency bands expand until they start to impinge on one
another. This spectrum serves as a metaphor for the changing relationship
between the instrumental group and the tape throughout Conversations.</FONT></P>

<P><FONT FACE="Times New Roman">Various processes were applied
to the sound sources of the tape by sections. In the first and
third sections FOF is the most prominent process, while in the
second section sounds produced by LPC predominate. Nevertheless,
possibly due to their common &quot;voiceness,&quot; there remains
a timbral unity to the tape, which is at times shown by the live
instruments.</FONT></P>

<P><FONT FACE="Times New Roman">In the first section, the tape
and the instrumental group were treated as two separate entities,
that begin to gradually overlap. In the second section, the core
of the piece, the two groups are clearly differentiated in a relationship
characteristic of the concerto grosso: the tape part is treated
as soli and the instruments as the ripieno. This is where the
metaphor of &quot;voiceness&quot; is most clearly audible. A type
of &quot;talking&quot; cross-synthesis was used in section two
using the processes explained above.</FONT></P>

<P><FONT FACE="Times New Roman">The timbral organization of the
tape part in the second section progresses from cross-synthesised
to perceptible speech sounds processed by LPC. From there on the
tape achieves a climax while returning to cross-synthesised timbres.
Following the climax, the tape features processed multiphonics.
The continuity between the first and second sections is achieved
through the use of live multiphonics.</FONT></P>

<P><FONT FACE="Times New Roman">During the third section, the
overlapping between instruments and tape is more general again.
Here the distinction between tape sounds and instrumental sounds
is blurred. At the end of this section, the voiced multiphonic
sounds of the instrumental part are related in timbre to the LPC
cross-synthesis techniques used in the previous section. This
is due to using the same words inside the live instruments that
were processed in the second section by LPC techniques. During
the coda the independence of both tape and instrumental group
is restored.&nbsp;<BR>
</FONT></P>

<H3><FONT FACE="Times New Roman">Conclusion</FONT></H3>

<P><I><FONT FACE="Times New Roman">Conversations</FONT></I><FONT
 FACE="Times New Roman"> was an exiting exploration in musical
sounds made possible by programs such as Csound and Lemur. The
possibility of using the opcodes FOF and LPC suggested speech
like-sounds that combined with those produced by extended techniques
suggested the general structure of the piece and the relationship
between the tape and performers. In retrospect, however, I wonder
how much more I could have done if the analysis and resynthesis
were possible in real time. This is a development that I am looking
forward to.</FONT></P>

<H3><FONT FACE="Times New Roman">References</FONT></H3>

<P><FONT FACE="Times New Roman">1) Charles Dodge and Thomas A.
Jerse, <I>Computer Music</I>, 1985</FONT></P>

<P><FONT FACE="Times New Roman">2) B. S. Atal and Suzanne L. Hanauer,
<I>Speech Analysis and Synthesis by Linear Prediction of the Speech
Wave,</I> 1971</FONT></P>

<H3><FONT FACE="Times New Roman">Acknowledgements</FONT></H3>

<P><FONT FACE="Times New Roman">I wish to thank Charles Dodge
for his valuable teaching on LPC techniques during my studies
at Dartmouth College.</FONT>

</BODY>
</HTML>
