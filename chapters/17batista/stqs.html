<html>	<head>		<meta http-equiv="content-type" content="text/html;charset=iso-8859-1">		<meta name="generator" content="Adobe GoLive 4">		<title>Neural Processing in Csound [ 1st Questions ]</title>		<meta name="Template" content="C:\Programas\Microsoft Office\Modelos\P&aacute;ginas da Web\Assistente de P&aacute;gina da Web.wiz">	</head>	<body bgcolor="white" link="blue" vlink="purple">		<font size="4" face="Times New Roman,Georgia,Times"><b>First Questions</b></font>		<p><font face="Times New Roman">First questions that arise are: what kind of net will I use, and what will I train the net with?</font></p>		<p><font face="Times New Roman">Well, the examples presented deal with pattern-association networks, so we'll focus on static non-recurrent networks, with or without hidden layers. Emphasis will be placed on the learning process. To use fast hebbian learning, we may at most create a pattern recognizer which will hold some three patterns, assuming they arent correlated. To be able to go past that we need slow back-propagation. First of all, we have the choice of lowering the control rate. Other possibilities include moving to frequency domain, having the net learn value differences instead of instantaneous values, or presenting a window of values to the net, instead of just a single one. Alternatively, resorting to some of the recent back-propagation extensions, may decrease learning time.</font></p>		<p><font face="Times New Roman">Recurrent nets, where the output is feedback to the input, thus learning some evolution of the training data, have not been considered here, due to the limited number of past values they can learn, and to the additional computational expense of those architectures. Nevertheless, they may be an interesting lead, if we overcome the referred limitations. It is very difficult to have a recurrent net learning values far in the past (the so called long-term dependencies), but maybe with the use of a delay line, or window methods, we can make some interesting applications, in the future, where evolution of audio (or non audio) data, is the learning material.</font></p>		<p><font face="Times New Roman">As you see, there's still a lot to try.</font></p>		<p><font face="Times New Roman">But what will the patterns be? Well, supposing they will be audio, amplitude or frequency values, there's the problem of neural networks not dealing so well with large values. One single neuron cant learn values from 20 to 20,000, for instance (theoretically it can, but the training method and duration, play a big role). It can usually learn a small continuous range like, but even there its very imprecise, and to get within say 10% of the desired value, it takes maybe thousands of iterations.</font></p>		<p><font face="Times New Roman">One of the best compromises, is still to use binary inputs and outputs. But then we have to find a way to encode the audio data in a binary form, without loosing definition. One clumsy attempt at this, is to simply use the binary encoded 16-bit sample value, and present it as a binary string to a 16 binary input network. The pitfall here is the fact that binary 1000000 is just next to 0111111, while to the network, these are very different patterns.</font></p>		<p><font face="Times New Roman">Maybe using a logarithmic coding (using the -6dB per bit rule) will improve results, but anyway there's need for a better encoding strategy. Another slight improvement resides in using some kind of Gray code for the binary value (Gray codes, are binary codings, where by definition, two consecutive values representations, only differ in a single bit). So, the problem with binary values, where for instance 01111 and 10000, although representing two consecutive numbers, differ by five digits, is overcome. This kind of encoding has been used in genetic algorithms, for the same reasons.</font></p>		<p><font face="Times New Roman">It is possible, using back-propagation and its variations, to use continuous neurons, instead of binary ones. Our later approaches will consider this, but at the expense of limited accuracy. It turns out that with real valued (not discrete) inputs and outputs, we cannot expect the net to learn precise representations. What we'll settle for, is getting the net within some narrow range from the exact solution. Our implementations will provide a precision factor, which will measure the amount of error (drift from the exact solution) we will allow. Using the same code, you can also 'quantize' the input and output values, so that you have not only binary, but ternary, quaternary, or n-ary neurons (the bigger the value of n, the smaller the allowed error must be). As will be shown, a higher precision net will turn out to be much harder to implement, and train.</font></p>		<p><font face="Times New Roman">My future projects will try to take into consideration the way the network &quot;thinks&quot;, as well as the way audio data behaves over time. We need a net that learns audio movement and time behavior, instead of just a sequence of still pictures of audio samples.&nbsp;</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<dir><font face="Times New Roman">Next : <a href="hebbian.html">Single layer training (hebbian learning)</a></font>			<p><font face="Times New Roman">Previous : <a href="network.html">Network basics</a></font></p>			<p><font face="Times New Roman">Up: <a href="index.html">Back to index</a></font>		</dir>	</body></html>