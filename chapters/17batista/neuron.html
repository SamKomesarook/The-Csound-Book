<html>	<head>		<meta http-equiv="content-type" content="text/html;charset=iso-8859-1">		<meta name="generator" content="Adobe GoLive 4">		<title>Neural Processing in Csound [ Basics 1]</title>		<meta name="Template" content="C:\PROGRAMAS\MICROSOFT OFFICE\OFFICE\HTML.DOT">	</head>	<body bgcolor="white" link="blue" vlink="purple">		<h3><font size="4" face="Times New Roman,Georgia,Times"><b>Neural Networks - The Basics</b></font></h3>		<h3><font face="Times New Roman"><b>The Biological Neuron</b></font></h3>		<p><font face="Times New Roman">The strength and effectiveness of our brain, is most certainly related to its structure. Brain processing isnt clearly separated among strictly delimited sections, in fact it appears to be distributed among millions of tiny cells called neurons, all working for a collective goal. It is accepted that there are specialized groups of these cells providing for specific tasks (say, a group deals with visual information reaching the brain, another group learns speech recognition and grammatical rules, other groups provide for locomotion and muscle coordination, etc), but even these specialized groups dont have a single cell doing a separate task, but instead a group of cells competing to collectively reach a suitable solution.</font></p>		<p><font face="Times New Roman">If all these cells, somehow act in unison, each of them providing for a small part of the solution, then they must have a way of connecting to each other, so that the overall response can be gathered from the collective effort. In fact we see that this neurons are very simple mechanisms when inspected individually, and their computational power comes from the synergy of a huge number of them, and most important, from the high degree of connectivity between them.</font></p>		<p><font face="Times New Roman">Biological neurons are interconnected by thin filaments, called dendrites. At the extremity of these connections, synapses occur, which are basically electrical bursts neurons can send to increase the stimulus level of the receiving neurons. Each neuron is virtually connected to thousands of others, and can influence the excitatory state of connected neurons by sending higher or lower stimulus over each connection. The state of each neuron is determined by the amount of energy it is receiving at each instant.</font></p>		<h3><font face="Times New Roman"><b>The Artificial Neuron</b></font></h3>		<p><font face="Times New Roman">The first model of an artificial neuron was proposed by Warren McCulloch and Walter Pitts in 1943. It consisted of a &quot;black-box&quot; with <i>n</i> inputs and a single output. The inputs would be connected to other neuron's outputs, so that each neuron would have <i>n</i> other neurons in its input, feeding it with a combined stimulus. The neuron's single output, would in turn be connected to yet other neurons, which would, as well, gather its input from a number of neurons, and once again present its single output to other neurons inputs.</font></p>		<p><font face="Times New Roman">This turned out to be a very crude model of a real neuron, since the binary nature (they just had an ON or OFF state) of these neurons was far from being a correct approximation of the virtual infinite range of values biological neurons can display.</font></p>		<p><font face="Times New Roman">In an artificial neuron's model, the output level, is determined by two factors:</font></p>		<ol>			<li><font face="Times New Roman">the level of excitatory stimulus being presented through each of the input connections</font>			<li><font face="Times New Roman">the strength of each of the neuron's input connections, through which the stimulus is fed to the neuron</font>		</ol>		<center>			<p><font face="Times New Roman"><img src="figures/01.gif" height="202" width="318"></font></p>		</center>		<p><font face="Times New Roman">Basically, each neuron has a threshold value which represents the minimum stimulus it needs to get activated (commonly referred to as <i>firing</i>). If the sum of all input stimulus the neuron receives, times their corresponding connection weights, exceeds some predetermined inertia value, then the neuron will itself output a stimulus burst in its output (the neuron will fire). If the added stimulus stays below that threshold, the neuron will not fire.</font></p>		<p><font face="Times New Roman">The McCulloch-Pitts neuron, being a binary neuron, would fire (output a one), if the weighted sum of its inputs exceeded a threshold, otherwise it would not fire (output a zero). More advanced approaches use continuous neurons, that can take inputs in a range of values (usually 0 to 1, or some symmetric range between <i>-x</i> and <i>+x</i>, with <i>x</i> being an arbitrary small value) and whose output is given by some continuous function usually also ranging from 0 to 1 (see the logistic function below). In any case this is, just to start with, still a huge limitation in comparison with real neurons, whose electro-chemical synapses take a virtually infinite range of values, capable of much finer processing.</font></p>		<p><font face="Times New Roman">The weights, or strengths of each of the connections, are also frequently a real number (a float), and in some optimized algorithms, even a signed integer value (for increased computational speed).</font></p>		<p><font face="Times New Roman">The resulting weighted sum of inputs that we computed for each neuron, is often further processed by an Activation Function, which computes this weighted sum and results in the actual neuron output. This activation function can be a number of things, but its usually either</font></p>		<ol>			<li><font face="Times New Roman">linear: the output of the neuron is a linear function of the weighted input amount (scaled by a gain factor G),</font>			<center>				<p><font face="Times New Roman"><img src="figures/form01.gif" height="32" width="158"></font></p>			</center>			<li><font face="Times New Roman">logistic: the output of the neuron follows the function,</font>		</ol>		<center>			<p><font face="Times New Roman"><img src="figures/form02.gif" height="62" width="172"></font></p>		</center>		<dir>			<dir><font face="Times New Roman">which is depicted as follows:</font>			</dir>		</dir>		<center>			<p><font face="Times New Roman"><img src="figures/7.gif" height="153" width="219"></font></p>		</center>		<p><font face="Times New Roman">In both cases, <i>net</i> equals the weighted sum of the neuron's inputs (just so that there are no doubts, it is the activation value of input neuron 1 times the weight of connection 1, plus the activation value of neuron 2 times the weight of connection 2, plus ...)</font></p>		<dir><font face="Times New Roman">&nbsp;</font>		</dir>		<p><font face="Times New Roman">So I guess we're ready to establish our artificial neuron's model, as</font></p>		<center>			<p><font face="Times New Roman"><img src="figures/2.gif" height="204" width="548"></font></p>		</center>		<p><font face="Times New Roman">Where:</font></p>		<p><font face="Times New Roman"><i>o(1), o(2), ..., o(n)</i>, are the activation values of the neurons connected to this neuron's input</font></p>		<p><font face="Times New Roman"><i>w(1)(j), w(2)(j), ..., w(n)(j)</i>, are the respective strengths of each of the connections on this neuron's input (which will be multiplied by the respective output of each of the input neurons)</font></p>		<p><font face="Times New Roman"><i>net(j)</i> is the weighted sum of all the input stimulus, times the respective connection strength, following the formula</font></p>		<center>			<p><font face="Times New Roman"><img src="figures/form03.gif" height="68" width="142"></font></p>		</center>		<p><font face="Times New Roman"><i>out(j)</i> is the actual output of the neuron (its activation) once the sum net(j) has been computed by the activation function, whatever that is.</font></p>		<center>			<p><font face="Times New Roman"><img src="figures/form04.gif" height="38" width="145"></font></p>		</center>		<p><font face="Times New Roman">		<hr>		</font></p>		<dir><font face="Times New Roman"><b>Next : </b><a href="network.html">Network basics</a></font>			<p><font face="Times New Roman"><b>Previous : </b><a href="intro.html">Introduction to neural networks</a></font></p>			<p><font face="Times New Roman"><b>Up:</b> <a href="index.html">Back to index</a></font>		</dir>	</body></html>