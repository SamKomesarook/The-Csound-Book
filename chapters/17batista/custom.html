<html>	<head>		<meta http-equiv="content-type" content="text/html;charset=iso-8859-1">		<meta name="generator" content="Adobe GoLive 4">		<title>Neural Processing in Csound [ Custom ]</title>		<meta name="Version" content="8.0.3612">		<meta name="Date" content="2/24/97">		<meta name="Template" content="C:\PROGRAMAS\MICROSOFT OFFICE\OFFICE\HTML.DOT">	</head>	<body text="black" bgcolor="white" link="blue" vlink="purple">		<h3><font size="4" face="Times New Roman,Georgia,Times"><b>Building a Custom Neural Implementation</b></font></h3>		<p><font face="Times New Roman">In this section I'll be showing how to use the generic RProp neural routines, we used for the tight encoder, to create a custom designed Csound neural implementation.</font></p>		<p><font face="Times New Roman">We have to consider some design issues, prior to writing our instrument:</font></p>		<ol>			<li><font face="Times New Roman">What will the training data be</font>			<li><font face="Times New Roman">How will the training data be coded</font>			<li><font face="Times New Roman">What is the minimum net morphology to deal with the training data</font>		</ol>		<p><font face="Times New Roman">The effectiveness of the answers we give to the preceding questions, will determine the success and overall performance of our instrument.</font></p>		<p><font face="Times New Roman">Questions #1 and #2 are intimately connected, since our coding strategy must suit the training data, in order to be effective. Since neuron's usually respond poorly to large ranges of input values, we must make an effort to present the net with data in a smaller range. For dealing with audio values, it may be better to use a logarithmic scale, which we can do very promptly with Csound using the dbamp( ) and ampdb( ) value converters. This would allow us to use values in the range 0 to 96 to describe the audio amp, obviously a much smaller range...</font></p>		<p><font face="Times New Roman">In the end we will always need to scale the input values to a small range, possibly a symmetric range like -1.0 to +1.0. For simplicity I will be using the input range from 0.0 to 1.0, as this is also the range in which our neurons produce output. Since we'll be using the sigmoid activation function, we need to center our values around 0.5, and keep in mind that values near this center value will be easier to learn, while a value of exactly 0.0 or 1.0 will take longer to reach.</font></p>		<p><font face="Times New Roman">Furthermore, we have the problem of neural nets having difficulty in achieving exact solutions. With our binary pattern scheme, an error of 40% would suffice, but if we need to get the response of the net inside a narrower error range to the target value, it may take many iterations. The compromise resides in using a number of steps within the [0.0:1.0] range, which will allow the encoding of more discrete values per neuron (for example, for binary inputs, two steps are defined, [0.0:0.5] and [0.5:1:0], but we may use smaller steps to encode more discrete values, packed together with increasing shorter distances). This steps (a sort of quantization), may allow us to recognize more complicated patterns, without requiring exact values (a value within the defined range, will be considered a hit). Alternatively, this number-of-steps factor can be viewed as a precision factor, if we define the admissible error range to be half the step size. Of course, a larger number of steps, while providing for more accurate results, will require more effort from the net, and will consequently demand a higher number of iterations.</font></p>		<p><font face="Times New Roman">The answer to the third question is almost a consequence of the answers to the first two. The input and output sizes depend on the problem at hand. Most problems I've considered involve learning some specific function, or mapping, from a set of input values, to some other group of output, or target patterns. Depending on what range of values this function deals with, some sort of encoding strategy will be needed to present these values to the net, converted to (and from) the intrinsic range of values our net will operate on. The coding strategy, will determine the net's input and output layers size. The accuracy we want for the net's recognition properties (in broad sense, both how many discrete steps you want encoded per neuron - in other words, how small should the admissible error be-, and the number of patterns you want to train), will determine how large the hidden layer should be.</font></p>		<p><font face="Times New Roman">The compromise resides in using an encoding scheme that preserves the training data's perceived characteristics but can be suitably converted to the network ideal form. And using the network's dimension that solves the problem, but is still small enough to perform fast.</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<h3><font face="Times New Roman"><b>Hidden Layer Size</b></font></h3>		<p><font face="Times New Roman">For the hidden layer, careful design must be done. If we stick to binary patterns, we can achieve Riedmiller's described results with 10-5-10 encoders, and even 12-2-12 ones, but with a broader range of values per neuron we need bigger &quot;intelligent&quot; hidden layers. Since we'll be using virtually random data, as training patterns, the net's required learning time may vary widely, regarding the 'simplicity' or 'complexity' of each particular training set. Riedmiller's experiments, focused on average conclusive results, used an organized set of patterns, all different, and spanning the whole range. To be realistic (if even that), anything that goes over three or four hundred iterations, is overwhelming. In the examples we use a maximum iteration constant, when the program gives up learning, which may be set to 1000, or less. If during the execution of the instrument, we start reaching this large amount of iterations, that tell's us we aint using a satisfactory net. To have something workable with RProp, our average number of iterations must be well below 200.</font></p>		<p><font face="Times New Roman">The hidden layer, must provide enough distributed processing power , to deal with the degree of accuracy we want from our particular implementation, and encoding scheme. I've read comments, and found some supporting evidence, that there is a &quot;sweet spot&quot; for hidden layer size (we are constricted to a single hidden layer in this particular implementation, but this remains the case both for hidden layer sizes and hidden layer number, in multiple-hidden-layer nets - in fact some adaptive algorithms start with a small net and grow hidden neurons or layers, as the learning process demands). With less neurons than this golden number, the net will have trouble learning the data, if it succeeds at all, but adding more hidden neurons, wont increase network performance, and most probably will start degrading it. Finding the exact required number of neurons, in this case, is achieved by the good old trial and error method, so there is need to experiment various settings, till you hit the perfect spot.</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<h3><font size="4" face="Times New Roman,Georgia,Times"><b>Network Testing</b></font><font face="Times New Roman"><br>		</font></h3>		<p><font face="Times New Roman">Finding the answers to the preceding questions, and assert the computational effort any given implementation will require, has lead me to adapt the encoder routines to a more flexible architecture, using customizable dimensions for input resolution and network size.</font></p>		<p><font face="Times New Roman">In this example you will be able to define:</font></p>		<p><font face="Times New Roman">		<table border="0" cellspacing="0" cellpadding="4" width="633">			<tr>				<td valign="top" width="16%"><font face="Courier New"><b>inump&nbsp;</b></font></td>				<td valign="top" width="84%">The number of patterns the net will have to learn (these are randomly created)</td>			</tr>			<tr>				<td valign="top" width="16%"><font face="Courier New"><b>istps</b></font></td>				<td valign="top" width="84%">The definition that the input and output values will have (number of steps)</td>			</tr>			<tr>				<td valign="top" width="16%"><font face="Courier New"><b>iisz</b></font></td>				<td valign="top" width="84%">The input size (number of values per input pattern)</td>			</tr>			<tr>				<td valign="top" width="16%"><font face="Courier New"><b>ihsz</b></font></td>				<td valign="top" width="84%">The number of cells in the hidden layer</td>			</tr>			<tr>				<td valign="top" width="16%"><font face="Courier New"><b>iosz</b></font></td>				<td valign="top" width="84%">The output size (number of values per input pattern)</td>			</tr>		</table>		&nbsp;</font></p>		<p><font face="Times New Roman">As an example, I've set the parameters to the case of a 1-16-1 network, with 4 step values (roughly, an error range of .125). If we then needed 2 input neurons instead of just one, we could get a working solution with less than twice this hidden size, but as I said, experimentation is crucial to find the perfect settings. Dont forget each iteration would take almost twice to run, then.</font></p>		<p><font face="Times New Roman">Check it out for yourself here, <a href="instruments/rptest.orc">RPTEST.ORC</a>, using the <a href="instruments/dummy.sco">DUMMY.SCO</a>.</font></p>		<p><font face="Times New Roman">Notice the fact that, quite awkwardly, the changes to the parameters must be made within the orchestra. While it seems that passing p-fields for each of the relevant parameters would be a more convenient way, the Zak space allocation, which is a function of the layer's sizes and the number of patterns used, could not be automatically sized from the score. We could simply allocate a huge size of Zak space, but that would consume more memory, so I decided to let those final improvements to the reader.</font></p>		<h3><font face="Times New Roman"><b>Discrete vs Continuous Neurons</b></font></h3>		<p><font face="Times New Roman">The istps variable was intended to provide for discrete valued neurons; this way, the input and output patterns, would be composed of a sequence of digits, each digit taking one of istps possible values. Considering each digit of the pattern can take one of n possible values 0,1,...,n-1, we would have to multiply this value for the step size (1/istps) to obtain the proper value in the [0.0:1.0] range, that we would present to the net. The training takes place until all output values are less than half the step size away from their respective targets. The output of the net, can then be 'quantized' in 1/istps sized steps, to obtain the discrete resulting value.</font></p>		<p><font face="Times New Roman">Alternatively, we can present the net with continuous values in the input range, and use the output of the net, as is, without any quantization, baring in mind, that we are allowing an error on the output. The training process on the net will be considered successful, as soon as the activation values output by the net, are all within a distance not larger than ierng, from the target values that we supplied for the training (possibly equal to the input patterns). But this deviation from the exact result, when scaled back to whatever was the original range, may result in wide variations from the intended response.</font></p>		<p><font face="Times New Roman">In the discrete case, the way the error affects performance, takes a different perspective, than in the continuous case. The net can be 100% exact, provided there are no recognition errors, while in the continuous case we're always allowing some degree of error. The problem with discrete, is we seldom settle for a single-input/single-output net, learning some 4 or 5 discrete values. Instead we need to encode our patterns, using a number of digits, which may be binary, but also ternary, or quaternary. Each particular encoding has its own limitations, since now a single digit recognized in error, may cause even wider deviations (the classic example of taking, say, binary 0000 and changing a single digit to obtain 1000...).</font></p>		<p><font face="Times New Roman">These routines (all back-prop based learning rules, actually), work with discrete as well as continuous data. You just have to make sure youre using a winning network definition. The only thing thats not originally coded is the quantization of the output values from the response to the stimulus pattern, after the training has succeeded. Since this activation of the net is stored in the output array, this choice retains the freedom of reading the value and using it either in discrete or continuous form.</font></p>		<h3><font face="Times New Roman"><b>A Note about Zak-space Allocation</b></font></h3>		<p><font face="Times New Roman">Whenever you change the network dimensions, or the number of patterns, you must update the zak space allocation size accordingly. To spare you the trouble of adding all array's sizes yourself, I provided a variable named i_end, which can be printed at the beginning of the instrument to inform you of the precise size needed. Just uncomment the print line. During the test phase, as you change net dimensions, you can just set the Zak size to a really big value that will let you run the instr, at the expense of some extra memory.</font></p>		<h3><font face="Times New Roman"><b>A Note about Random Generators</b></font></h3>		<p><font face="Times New Roman">This results have been using the rnd( ) function to provide for the randomness required for the initial weights, and in this case, the patterns themselves. Both of these factors (start values, and data patterns) have a big influence on the outcome, and so, a different random function, and other kinds of training patterns (for instance, obtained from real audio data), may allow much finer resolution, while remaining practicable. Experimentation is the only way to find out.</font></p>		<p><font face="Times New Roman">One little adjustment (that I've kept out for simplicity), is using a proper seeded random generator for the weight initialization. This means the weight initialization code has to be moved to the performance section, prior to the reinit, but it will allow at least, experimenting with different series of random numbers (by using different seeds), which may have a big influence on the results.</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<p><font face="Times New Roman">Now, after experimenting with this example, you will soon realize, what can be done with your network of choice, and at what expense. There's no point in going any further, until you decided on the answers to all three of the above questions, and are ready to integrate this neural routines into a complete application, confident it is a realistic approach. Unfortunately, the results you arrive here, are not conclusive. The actual data you'll be training the net with has a determining role, and only with further optimization, after the whole instrument is complete, will you reach an optimal architecture.</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<h3><font size="4" face="Times New Roman,Georgia,Times"><b>The Customizable Neural Routines</b></font></h3>		<p><font face="Times New Roman">This set of routines implements an RProp trained neural network, capable of dealing with discrete or continuous data, and it has always been my goal to construct this code as some sort of 'black-box' that can be applied to whatever training data.</font></p>		<p><font face="Times New Roman">You have the freedom of choosing what the training data will be, but it will be your responsibility to come up with an encoding scheme that will allow you to convert the data to the range where the net operates. After you have the data in a suitable form, you just place it in a buffer area (the pattern area, in Zak space), and then call the neural processing routines. What these routines do, need not be your concern, as you can rest assure the resulting data will at the end be placed in the buffer area, from where you can quite conveniently read it, after the training is accomplished. This resulting data will most certainly required further processing to bring it back to its original range, from the net range it was converted to.</font></p>		<p><font face="Times New Roman">The neural routines and program skeleton are here : <a href="instruments/custom.orc">CUSTOM.ORC</a></font></p>		<p><font face="Times New Roman">To run this instrument, you will need a score. The <a href="instruments/dummy.sco">DUMMY.SCO</a> we've been using does the job, but at this point, you may consider passing a little more info on the instrument activation line. This will of course depend on the actual application you are constructing, and you will see an example in the particular case that is discussed for the remaining of this section. What you should consider is passing enough information from the score, that will prevent changing the orchestra, for different parameterizations of the instrument.</font></p>		<h3><font face="Times New Roman"><b>Calling the Neural Routines</b></font></h3>		<p><font face="Times New Roman">The way I've devised it, you can use the neural routines quite simply, over your chosen data, by filling the input and output pattern arrays with the training set (you'll have to generate that training set, using a- or k-rate code), and then merely calling a neural 'subroutine', with the reinit/rireturn method. What the program does during the reinit portion (the neural processing itself) should not concern you (except for didactic purposes), as you can view this routines as a black box, that just performs some processing on the data you feed to it.</font></p>		<p><font face="Times New Roman">The input and output patterns are placed sequentially in their Zak-space area. Space must be allocated for an additional input/output pair that serves a special purpose. The additional input pattern (after all other input patterns) is the stimulus pattern, that is, the pattern you use to test the net, after training has taken place. The additional output pattern (also after all other output patterns) is where the response from the trained net, to the stimulus pattern, will be stored, so that you can read it and use it, after the neural routines have been called.</font></p>		<p><font face="Times New Roman">All you have to do is place a number of patterns (equal to inump), in the input array, place an equal number of patterns in the output array, and place an additional stimulus pattern after all input patterns. Then call the neural routines. You do this on the instruction:</font></p>		<dir>			<dir><font size="2" face="Courier New">reinit neural</font>			</dir>		</dir>		<p><font face="Times New Roman">This puts you in charge of exactly when you want the neural net to be built and trained. The neural routines will do their thing, and eventually they will encounter a rireturn, after which execution resumes just after the reinit instruction. You just have to read the response pattern from the end of the output array, and use it as you see fit.</font></p>		<p><font face="Times New Roman">You must not forget, that although this net performs as some sort of black-box, it operates with values in the [0.0:1.0] range. Most of the times the training material is not in this range, and there is need to convert it to a number of values in the proper range, prior to presenting it to the net. Conversely, the response from the net must be scaled back from this net range, before its used.</font></p>		<h3><font face="Times New Roman"><b>Writing to the Input and Output Pattern Area</b></font></h3>		<p><font face="Times New Roman">After you've somehow generated a value in the [0.0:1.0] range, or some small symmetric range of your choice, to act as training data, it must be placed in the input/output pattern arrays, in Zak space. There is separate input and output area, where all respective patterns are stored before training begins. Constants i_in, and i_out, denote respectively input and output array starts. Each of the inump patterns, is stored sequentially, occupying either iisz (input size) or iosz (output size) chunks.</font></p>		<p><font face="Times New Roman">To help visualize things, here is a memory map of zak space for the input array:		<table border="0" cellspacing="0" cellpadding="4" width="632">			<tr>				<td valign="top" width="50%"><font size="4"><u><b>Position</b></u></font></td>				<td width="50%"><font size="4"><u><b>Content</b></u></font></td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in ]</td>				<td valign="top" width="50%">Pattern A - bit 1</td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in ] + 1</td>				<td valign="top" width="50%">Pattern A - bit 2</td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in ] + 2</td>				<td valign="top" width="50%">Pattern A - bit 3</td>			</tr>			<tr>				<td valign="top" width="50%">...</td>				<td valign="top" width="50%">...</td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in ] + ( iisz - 1 )</td>				<td valign="top" width="50%">Pattern A - bit iisz</td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in + 1 * iisz ]</td>				<td valign="top" width="50%">Pattern B - bit 1</td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in + 1 * iisz ] + 1</td>				<td valign="top" width="50%">Pattern B - bit 2</td>			</tr>			<tr>				<td valign="top" width="50%">...</td>				<td valign="top" width="50%">...</td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in + 1 * iisz ] + ( iisz - 1 )</td>				<td valign="top" width="50%">Pattern B - bit iisz</td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in + 2 * iisz ]</td>				<td valign="top" width="50%">Pattern C - bit 1</td>			</tr>			<tr>				<td valign="top" width="50%">...</td>				<td valign="top" width="50%">...</td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in + 2 * iisz ] + ( iisz - 1 )</td>				<td valign="top" width="50%">Pattern C - bit iisz</td>			</tr>			<tr>				<td valign="top" width="50%">...</td>				<td valign="top" width="50%">...</td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in + inump * iisz ]</td>				<td valign="top" width="50%">Stimulus Pattern - bit 1</td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in + inump * iisz ] + 1</td>				<td valign="top" width="50%">Stimulus Pattern - bit 2</td>			</tr>			<tr>				<td valign="top" width="50%">...</td>				<td valign="top" width="50%">&nbsp;</td>			</tr>			<tr>				<td valign="top" width="50%">[ i_in + inump * iisz ] + ( iisz - 1 )</td>				<td valign="top" width="50%">Stimulus Pattern - bit iisz</td>			</tr>		</table>		&nbsp;</font></p>		<p><font face="Times New Roman">The structure of the output array, is similar, with i_in substituted for i_out, iisz substituted for iosz, and the response pattern instead of the stimulus pattern.</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<h3><font size="4" face="Times New Roman,Georgia,Times"><b>One Possible Implementation: A Sample Recognizer</b></font></h3>		<p><font face="Times New Roman">Since for the time being, I'm mostly concerned in getting the neural routines working effectively, and havent yet considered more clever uses in sonic domain, I will continue to develop a &quot;sample-recognizer&quot;, similar to what has been devised in the BAM section, only more powerful, using RProp training, which will allow more and more complicate patterns to be learned. Hopefully while discussing this particular case, it will be show how easy it is to adapt this neural routines to deal with generic data, generated any other way.</font></p>		<p><font face="Times New Roman">I've dissociated the neural and performance sections of the processing, so that you can use any means of data generating at k-time, fill the input and output arrays with all the patterns, and then call the neural routines to do their thing, via the reinit/rireturn scheme. This way, all you have to do is devise the k-rate section, where audio is encoded and decoded to the appropriate neural net range, and keep the neural routines intact.<br>		</font><font face="Times New Roman">&nbsp;&nbsp;</font></p>		<p><font face="Times New Roman"><b>The Coding Examples</b></font></p>		<p><font face="Times New Roman">To help me consider different encoding schemes, I've devised a series of skeleton programs, only concerned with the audio encoding/decoding instructions. After experimenting with these, I can incorporate the neural routines, confident the audio scheme does work.</font></p>		<p><font face="Times New Roman">The simplest encoding strategy we'll be using, assumes we're dealing with amp values in the range -32768 to +32767, and then offsets this range to the 0 to 65536 range, by adding 32768 to the value. This offset value, is then scaled to the [0.0:1.0] range, by dividing it by 65536. The final value will be training data.</font></p>		<p><font face="Times New Roman">Check the encoding/decoding routines here: <a href="instruments/coding1.orc">CODING1.ORC</a></font></p>		<p><font face="Times New Roman">Next, and since as we've seen, 0 to 65536 is such a huge range, we may try to use a dB value instead, using the dbamp( ) and ampdb( ) value converters. We will still have to offset the initial value to the 0 to 65535 range, prior to calculating the dB equivalent, and this time we will rescale this dB value to the [0.0:1.0] range, by dividing it by 96. This is actually worse, since our 'allowed error', converted back in a logarithmic fashion, leads to much wider fluctuations, and a much noisier result.</font></p>		<p><font face="Times New Roman">You can see for yourself how, here: <a href="instruments/coding2.orc">CODING2.ORC</a></font></p>		<p><font face="Times New Roman">Finally, a better approach stems from the fact that we'll be using a relatively small number of values (patterns) to train the net each time (at k-rate), and so, the dynamic range the net has to deal with, is not the whole 96dB, but depends on the pattern data themselves, which may be more or less smeared. Then, to take advantage of this fact, and in order to use a less precision net, we can find out the minimum and maximum value that is trained each time (across every patterns), and with this min and max values, use a scaled value equal to ( value + min ) / ( max - min ). This will keep all values in the [0.0:1.0] range.</font></p>		<p><font face="Times New Roman">Here is a possible code <a href="instruments/coding3.orc">CODING3.ORC</a> to support a more advanced implementation you'll find below. As you can check later on, this is the best coding scheme, as it minimizes the inherent error.</font></p>		<p><font face="Times New Roman">And again the <a href="instruments/dummy.sco">DUMMY.SCO</a> to let you run all the examples.</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<h3><font face="Times New Roman"><b>The 'Morpher' Instrument</b></font></h3>		<p><font face="Times New Roman">Finally we're able to put all the pieces together and form a full application. I called this instrument a morpher, but it really is just an inaccurate sample recognizer, which because of its weakness, more or less scrambles the learned patterns (samples). Since we settle for some degree of error in the output, we are varying the samples amplitude, thus introducing random amp changes, which result in noise. This will show more on the worse encoding methods, and will become quite neglectable on the final encoding strategy. To get better results, we may lower the admissible error, which will possibly demand more hidden neurons, but will certainly require more iterations. This instrument is too slow already, so, a number of steps (istps) larger than 10, will be impracticable.</font></p>		<p><font face="Times New Roman">I tried the three encoding methods mentioned above; the respective instruments, are presented here just as examples. The simplest encoding scheme (a linear mapping across the amplitude range), leads to fluctuations on the output, when the admissible error is converted back to the audio dynamic range, which results in noise (<a href="instruments/morpher1.orc">MORPHER1.ORC</a>).</font></p>		<p><font face="Times New Roman">Using a dB conversion of the amplitude values, in order to use a smaller range, ends up in an even noisier output. This is because our allowed error, when converted back from a logarithmic scale, yields even wider deviations (<a href="instruments/morpher2.orc">MORPHER2.ORC</a>).</font></p>		<p><font face="Times New Roman">Finally, the <a href="instruments/morpher3.orc">MORPHER3.ORC</a>, uses a cleverer encoding algorithm, calculating the necessary dynamic range for each pattern set, in order to reduce the scaling factor. This will lead to best (less noisy) results, as you may verify. For now run it with the <a href="instruments/dummy.sco">DUMMY.SCO</a>.</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<h3><font face="Times New Roman"><b>Dimensioning and Monitoring the Instrument</b></font></h3>		<p><font face="Times New Roman">After you have a working model, and in order to get the best of it, you may try to increase the resolution, by providing a higher value for the istps constant. You may also wish to vary the hidden layer size, so that you discover the minimum sufficient size. But as this may cause the network to diverge occasionally, you should uncomment the print instruction on the converge section,</font></p>		<p><font size="2" face="Courier New">done: ; print iter</font></p>		<p><font face="Times New Roman">and run the instrument for a while, making sure the average number of iterations is still small. Then you can comment the print again, and let the instrument run to completion, confident it is performing well.</font></p>		<p><font face="Times New Roman">If the number of iterations starts getting big (and specially if it reaches the give up point of imaxit), meaning the net is having trouble finding solutions, you either have to lower the resolution, or increase the hidden layer size.</font></p>		<p><font face="Times New Roman">What we want to find, is the minimum, less accurate network, that still performs the job. Remember that the number of patterns you use, is also a determining constraint. The net size you choose, when using, say, three patterns, may have trouble when learning five. You should perform the dimensioning, with the actual maximum number of patterns you'll be using.</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<h3><font size="4" face="Times New Roman,Georgia,Times"><b>The Final Version</b></font></h3>		<p><font face="Times New Roman">Here I present the final version of the sampler recognizer, using a proper score file and up to four training patterns. You dont need to edit the orchestra code any more, since all relevant parameters can be set from inside the score.</font></p>		<p><font face="Times New Roman">First you must supply soundin numbers for up to four patterns, and an additional one for a stimulus pattern. If you dont need all four patterns, just supply the leftmost ones, and set the number of patterns field to reflect the number of patterns in use. The remaining (to the right) pattern soundin numbers will be ignored. Dont forget to supply the stimulus pattern soundin number at the end.</font></p>		<p><font face="Times New Roman">Depending on the number of patterns, we wont always be needing a hidden layer as big as 32 cells, which takes a lot of processing time. The solution will be to dynamically size the hidden layer, proportionally to the number of patterns. For that matter, a table is used, having the hidden sizes for one up to four patterns. Actually, the hidden size is also a matter of how small you want the allowed error to be. With more 'steps', you will need bigger hidden layer sizes.</font></p>		<p><font face="Times New Roman">For commodity, the precision factor, is also passed, through the steps parameter. This will allow you to mess with several values, all directly related with performance time, in a centralized way.</font></p>		<p><font face="Times New Roman">One of the biggest limitations of this implementation is the fact that there is absolutely no learning of the audio evolution over time. At each k-rate pass, a net is trained with up to 4 patterns, in a complete non-causal fashion. To be able to learn audio evolution, the net would need memory, making it a recurrent net. This rises all sorts of problems, and could alone be the subject to a whole new paper. It remains one of my goals for the future, nevertheless.</font></p>		<p><font face="Times New Roman">As a consequence of the design, the output is rather noisy, as consecutive samples are not related (dependent) in value (there is no time dependency), and can seem erratic. I tried applying a moving average to the output series, which improved a lot the final sound (we can now hear the bass sounds!). The moving average calculation requires holding n previous values in memory, which is done using a function table (number iavrt). The average window is iavrw values wide. I used a table size of 128, but it can be expanded for slightly better quality (only slower performance). At each k-rate cycle, the table is flushed one position, freeing space for the current output value at the end. The effective output value is then the averaged sum of the whole table.</font></p>		<p><font face="Times New Roman">Lets see, then, an example of the instrument activation line: To train the network with 5 steps (an error of 10%) and the whole 4 patterns, respectively soundin.1, soundin.10, soundin.20 and soundin.99, and test the trained result with stimulus pattern soundin.15, running for 1.5 seconds, you may use this score:</font></p>		<p><font face="Times New Roman">		<table border="0" cellspacing="0" cellpadding="4" width="571">			<tr>				<td valign="top" width="8%"><font size="2" face="Courier New">;</font></td>				<td valign="top" width="12%">					<center>						<font size="2" face="Courier New">Str</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">Dur</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">Steps</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">NumPat</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">Pat1</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">Pat2</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">Pat3</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">Pat4</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">Stim</font></center>				</td>			</tr>			<tr>				<td valign="top" width="8%"><font size="2" face="Courier New">i1</font></td>				<td valign="top" width="12%">					<center>						<font size="2" face="Courier New">0</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">1.5</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">5</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">4</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">1</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">10</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">20</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">99</font></center>				</td>				<td valign="top" width="10%">					<center>						<font size="2" face="Courier New">15</font></center>				</td>			</tr>		</table>		</font><font face="Times New Roman">&nbsp;</font></p>		<p><font face="Times New Roman">Remember this is a slow instrument, and the more patterns you use, or the higher steps (lower error) you demand from the net, the slower it will perform. Desolated, but thats how it works.</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<p><font face="Times New Roman">Here's the final orchestra <a href="instruments/morpher.orc">MORPHER.ORC</a> and score <a href="instruments/morpher.sco">MORPHER.SCO</a>.<br>		</font><font face="Times New Roman">&nbsp;&nbsp;		<hr>		</font></p>		<p><font face="Times New Roman">You may want to change the control rate in the orchestra, for speed reasons, although values of ksmps above 10, start degrading the output (which may be interesting, if youre looking for a grungier sound). You may also decrease the precision (by lowering the value for istps), if you wish to limit the instrument's recognition properties. This will increase performing speed a little.</font></p>		<p><font face="Times New Roman">Fun starts when you stimulate the net with samples different from those that were trained. In theory (and you can see some evidence with this instrument) this will cause the net to respond with whichever known sample more resembles the stimulus sample (since we trained the net in auto-association). An independent net is trained for each control rate, so the result will probably oscillate between the learned patterns, depending on the stimulus at each time. This results in some mangling of the input samples, hence the 'morphing' characteristic of this instrument.</font></p>		<p><font face="Times New Roman">I've tried several stimulus, ranging from white and pink noise, to pure waveforms (sinus, saw, square) at specific tones, trying some conventional drum, bass, piano or strings sounds on the way. One should expect the stimulus signal to have more effect on the output sound, but the truth is it doesnt, specially with few training patterns. But still there is some penetration of the stimulus, that can be clearly heard sometimes, so its worth to suit the stimulus to your needs. Even if its not immediately perceived, it is there. In my opinion, the best stimulus should have resemblance with the trained material, without being too similar (correlated) to any of the trained patterns.</font></p>		<p><font face="Times New Roman">Theres no reason why the stimulus signal cant be generated within Csound. We may be able to calculate the best stimulus, according to how we want the network to respond. You just provide any form of audio generation, other that soundin, for the stimulus code within the performance section, and feed that at k-rate, acting as stimulus.</font></p>		<p><font face="Times New Roman">You can hear some <a href="sounds.html">sound examples</a>, that were generated using this instrument.</font></p>		<h3><font face="Times New Roman"><b>Limitations</b></font></h3>		<p><font face="Times New Roman">This instrument has some limitations, due to its design. First of all its very noisy, making it more suitable for 'harsh' sounds, or unusual sound generation. Second, it runs very slow, which severely compromises the usefulness of something that should be first of all prone to experimentation. Two or three patterns, with a large allowed error of .125 (4 steps), are what most I can expect from my PC, to keep running time within few minutes (two/three minutes per second of generated audio).</font></p>		<p><font face="Times New Roman">These results could be improved with some audio processing afterwards. Specifically, normalizing (which would require two passes through the resulting audio, one for finding the dynamic range and another to rescale the audio, so maybe we're stuck with variable amplification gain) and equalizing the resulting audio. This can be added to the end of the instrument with little effort, and is left as exercise for the reader.</font></p>		<p><font face="Times New Roman">I'm afraid I cant think of much more that can be done, keeping the same premises. Only better encoding strategies, and audio understanding algorithms, can lead to better results.</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<dir><font face="Times New Roman"><b>Next : </b><a href="whatnext.html">What next?</a></font>			<p><font face="Times New Roman"><b>Previous : </b><a href="encoder.html">Testing RProp with a tight encoder</a></font></p>			<p><font face="Times New Roman"><b>Up:</b> <a href="index.html">Back to index</a></font>		</dir>	</body></html>