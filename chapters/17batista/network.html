<html>	<head>		<meta http-equiv="content-type" content="text/html;charset=iso-8859-1">		<meta name="generator" content="Adobe GoLive 4">		<title>Neural Processing in Csound [ Basics 2 ]</title>		<meta name="Template" content="C:\PROGRAMAS\MICROSOFT OFFICE\OFFICE\HTML.DOT">	</head>	<body bgcolor="white" link="blue" vlink="purple">		<h3><font size="4" face="Times New Roman,Georgia,Times"><b>Neural Networks - The Basics</b></font></h3>		<h3><font face="Times New Roman"><b>The Network Structure</b></font></h3>		<p><font face="Times New Roman">So we've seen that a neuron can be fully described by both, its activation function(s), and the set of its input weights. But to have some practical use, we must group these neurons in what is commonly referred as a layer. A layer is merely an array of neurons. The simplest network will have just a single layer, comprised of n neurons and their respective connections. To help visualize things, lets consider a simple network which will have a single layer, comprised of two neurons. Each of these two neurons will be connected to the two network inputs, and their respective output values will consist of the network's (two) outputs:</font></p>		<center>			<dir><font face="Times New Roman"><img src="figures/3.gif" height="206" width="287"></font>			</dir></center>		<p><font face="Times New Roman">As we see from this picture, the actual layer is enclosed by the dashed rectangular box. It consists of the two neurons (the circles a1 and a2), and their respective weights (w11, w12, w21 and w22). The square boxes represent the input of the net, where an input pattern is placed. Usually, each of the neurons is connected to every single input cell, but not connected to other neurons in the same layer, although that may vary accordingly to the desired network behavior. There is also a common practice of referring to the input (in this example the square boxes) as a layer in itself, but I prefer to call it a layer only when describing a group of neurons with respective input connections, and consider the input to be just a buffer area from where input values are presented to the net.</font></p>		<p><font face="Times New Roman">Since this network has only one layer, the output of this one layer (the two arrows coming out of a1 and a2) is the actual output of the net. This need not be the case, since the network could consist of any number of layers. If there were more layers, the output of layer 1 would have been fully connected to the input of each neuron in the subsequent layer 2, and so forth. So, each layer receives activation from previous cells (either the input cells, or each of the neurons in the preceding layer), and forwards its output to following cells (to either the network output, or each of the neurons in the subsequent layer).</font></p>		<center>			<dir><font face="Times New Roman"><img src="figures/4.gif" height="104" width="324"></font>			</dir></center>		<p><font face="Times New Roman">Please notice that for simplicity the picture depicts all layers as having only two neurons each. This need not be the case, as the input size, and each of the layer's sizes, can take any dimension (with the obvious expense of processing time). But in any case, each of the layer's neurons will be connected to each and every cell in the preceding layer.</font></p>		<p><font face="Times New Roman">In the following material, the convention used to refer to the network arrays (where the activation of each neuron, plus the strengths of each connection, plus other relevant data is stored) will remain consistently as follows (in C style):</font></p>		<p><font face="Times New Roman">A[L][I] - the activation value for neuron I, in layer L</font></p>		<p><font face="Times New Roman">W[L][J][K] - the weight of the connection between cell J in the input layer L-1, and cell K in layer L</font></p>		<p><font face="Times New Roman">So, for example</font></p>		<p><font face="Times New Roman">A[1][3] will be the activation state of neuron 3 in layer 1</font></p>		<p><font face="Times New Roman">W[2][4][1] will be the weight of the connection between cell 4 of layer 1, and cell 1 of layer 2<br>		&nbsp;&nbsp;</font></p>		<p><font face="Times New Roman">		<hr>		</font></p>		<dir><font face="Times New Roman"><b>Next : </b><a href="stqs.html">First questions</a></font>			<p><font face="Times New Roman"><b>Previous : </b><a href="neuron.html">Neuron basics</a></font></p>			<p><font face="Times New Roman"><b>Up:</b> <a href="index.html">Back to index</a></font>		</dir>	</body></html>